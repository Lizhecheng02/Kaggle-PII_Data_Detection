{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-28T00:44:28.299480Z",
     "iopub.status.busy": "2024-01-28T00:44:28.299148Z",
     "iopub.status.idle": "2024-01-28T00:44:28.334909Z",
     "shell.execute_reply": "2024-01-28T00:44:28.333697Z",
     "shell.execute_reply.started": "2024-01-28T00:44:28.299448Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAINING_MODEL_PATH = \"microsoft/deberta-v3-large\"  # your model path\n",
    "TRAINING_MAX_LENGTH = 768  # I use 1280 locally\n",
    "OUTPUT_DIR = \"output\"  # your output path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-28T00:44:28.337516Z",
     "iopub.status.busy": "2024-01-28T00:44:28.337040Z",
     "iopub.status.idle": "2024-01-28T00:44:50.933214Z",
     "shell.execute_reply": "2024-01-28T00:44:50.931337Z",
     "shell.execute_reply.started": "2024-01-28T00:44:28.337471Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install seqeval evaluate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-28T00:44:50.935796Z",
     "iopub.status.busy": "2024-01-28T00:44:50.935337Z",
     "iopub.status.idle": "2024-01-28T00:45:16.963350Z",
     "shell.execute_reply": "2024-01-28T00:45:16.960988Z",
     "shell.execute_reply.started": "2024-01-28T00:44:50.935753Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "from transformers import AutoTokenizer, Trainer, TrainingArguments\n",
    "from transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification\n",
    "from datasets import Dataset, features, DatasetDict\n",
    "from seqeval.metrics import recall_score, precision_score\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-28T00:45:16.968460Z",
     "iopub.status.busy": "2024-01-28T00:45:16.967406Z",
     "iopub.status.idle": "2024-01-28T00:45:20.419334Z",
     "shell.execute_reply": "2024-01-28T00:45:20.418395Z",
     "shell.execute_reply.started": "2024-01-28T00:45:16.968406Z"
    }
   },
   "outputs": [],
   "source": [
    "data = json.load(open(\"../kaggle_dataset/competition/train.json\"))\n",
    "\n",
    "print(len(data))\n",
    "print(data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-28T00:45:20.421306Z",
     "iopub.status.busy": "2024-01-28T00:45:20.420749Z",
     "iopub.status.idle": "2024-01-28T00:45:20.521870Z",
     "shell.execute_reply": "2024-01-28T00:45:20.520502Z",
     "shell.execute_reply.started": "2024-01-28T00:45:20.421271Z"
    }
   },
   "outputs": [],
   "source": [
    "all_labels = sorted(list(set(chain(*[x[\"labels\"] for x in data]))))\n",
    "label2id = {l: i for i, l in enumerate(all_labels)}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-28T00:45:20.524203Z",
     "iopub.status.busy": "2024-01-28T00:45:20.523626Z",
     "iopub.status.idle": "2024-01-28T00:45:20.531176Z",
     "shell.execute_reply": "2024-01-28T00:45:20.529451Z",
     "shell.execute_reply.started": "2024-01-28T00:45:20.524163Z"
    }
   },
   "outputs": [],
   "source": [
    "target = [\n",
    "    \"B-EMAIL\", \"B-ID_NUM\", \"B-NAME_STUDENT\", \"B-PHONE_NUM\",\n",
    "    \"B-STREET_ADDRESS\", \"B-URL_PERSONAL\", \"B-USERNAME\", \"I-ID_NUM\",\n",
    "    \"I-NAME_STUDENT\", \"I-PHONE_NUM\", \"I-STREET_ADDRESS\", \"I-URL_PERSONAL\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-28T00:45:20.534409Z",
     "iopub.status.busy": "2024-01-28T00:45:20.533806Z",
     "iopub.status.idle": "2024-01-28T00:45:20.552138Z",
     "shell.execute_reply": "2024-01-28T00:45:20.550320Z",
     "shell.execute_reply.started": "2024-01-28T00:45:20.534358Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(example, tokenizer, label2id):\n",
    "    text = []\n",
    "\n",
    "    # these are at the character level\n",
    "    labels = []\n",
    "    targets = []\n",
    "\n",
    "    for t, l, ws in zip(example[\"tokens\"], example[\"provided_labels\"], example[\"trailing_whitespace\"]):\n",
    "\n",
    "        text.append(t)\n",
    "        labels.extend([l] * len(t))\n",
    "\n",
    "        if l in target:\n",
    "            targets.append(1)\n",
    "        else:\n",
    "            targets.append(0)\n",
    "        # if there is trailing whitespace\n",
    "        if ws:\n",
    "            text.append(\" \")\n",
    "            labels.append(\"O\")\n",
    "\n",
    "    tokenized = tokenizer(\n",
    "        \"\".join(text), \n",
    "        return_offsets_mapping=True,\n",
    "        truncation=True, \n",
    "        max_length=TRAINING_MAX_LENGTH\n",
    "    )\n",
    "\n",
    "    target_num = sum(targets)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    text = \"\".join(text)\n",
    "    token_labels = []\n",
    "\n",
    "    for start_idx, end_idx in tokenized.offset_mapping:\n",
    "\n",
    "        # CLS token\n",
    "        if start_idx == 0 and end_idx == 0:\n",
    "            token_labels.append(label2id[\"O\"])\n",
    "            continue\n",
    "\n",
    "        # case when token starts with whitespace\n",
    "        if text[start_idx].isspace():\n",
    "            start_idx += 1\n",
    "\n",
    "        token_labels.append(label2id[labels[start_idx]])\n",
    "\n",
    "    length = len(tokenized.input_ids)\n",
    "\n",
    "    return {\n",
    "        **tokenized,\n",
    "        \"labels\": token_labels,\n",
    "        \"length\": length,\n",
    "        \"target_num\": target_num,\n",
    "        \"group\": 1 if target_num > 0 else 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-28T00:45:20.554772Z",
     "iopub.status.busy": "2024-01-28T00:45:20.554317Z",
     "iopub.status.idle": "2024-01-28T00:45:24.241034Z",
     "shell.execute_reply": "2024-01-28T00:45:24.239650Z",
     "shell.execute_reply.started": "2024-01-28T00:45:20.554721Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TRAINING_MODEL_PATH)\n",
    "\n",
    "ds = Dataset.from_dict({\n",
    "    \"full_text\": [x[\"full_text\"] for x in data],\n",
    "    \"document\": [str(x[\"document\"]) for x in data],\n",
    "    \"tokens\": [x[\"tokens\"] for x in data],\n",
    "    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n",
    "    \"provided_labels\": [x[\"labels\"] for x in data],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-28T00:45:24.243331Z",
     "iopub.status.busy": "2024-01-28T00:45:24.242754Z",
     "iopub.status.idle": "2024-01-28T00:51:17.766470Z",
     "shell.execute_reply": "2024-01-28T00:51:17.764740Z",
     "shell.execute_reply.started": "2024-01-28T00:45:24.243278Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ds = ds.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer, \"label2id\": label2id}, num_proc=2)\n",
    "ds = ds.class_encode_column(\"group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-28T00:51:17.769301Z",
     "iopub.status.busy": "2024-01-28T00:51:17.768657Z",
     "iopub.status.idle": "2024-01-28T00:51:17.793322Z",
     "shell.execute_reply": "2024-01-28T00:51:17.791499Z",
     "shell.execute_reply.started": "2024-01-28T00:51:17.769255Z"
    }
   },
   "outputs": [],
   "source": [
    "x = ds[0]\n",
    "\n",
    "for t, l in zip(x[\"tokens\"], x[\"provided_labels\"]):\n",
    "    if l != \"O\":\n",
    "        print((t, l))\n",
    "\n",
    "print(\"*\" * 40)\n",
    "\n",
    "for t, l in zip(tokenizer.convert_ids_to_tokens(x[\"input_ids\"]), x[\"labels\"]):\n",
    "    if id2label[l] != \"O\":\n",
    "        print((t, id2label[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competition Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-28T00:51:17.796094Z",
     "iopub.status.busy": "2024-01-28T00:51:17.795038Z",
     "iopub.status.idle": "2024-01-28T00:51:17.810828Z",
     "shell.execute_reply": "2024-01-28T00:51:17.809992Z",
     "shell.execute_reply.started": "2024-01-28T00:51:17.796054Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, all_labels):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [all_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [all_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    recall = recall_score(true_labels, true_predictions)\n",
    "    precision = precision_score(true_labels, true_predictions)\n",
    "    f1_score = (1 + 5 * 5) * recall * precision / (5 * 5 * precision + recall)\n",
    "\n",
    "    results = {\n",
    "        \"recall\": recall,\n",
    "        \"precision\": precision,\n",
    "        \"f1\": f1_score\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-28T00:51:17.813460Z",
     "iopub.status.busy": "2024-01-28T00:51:17.812306Z",
     "iopub.status.idle": "2024-01-28T00:51:30.658590Z",
     "shell.execute_reply": "2024-01-28T00:51:30.657204Z",
     "shell.execute_reply.started": "2024-01-28T00:51:17.813415Z"
    }
   },
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    TRAINING_MODEL_PATH,\n",
    "    num_labels=len(all_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-28T00:51:30.663945Z",
     "iopub.status.busy": "2024-01-28T00:51:30.663529Z",
     "iopub.status.idle": "2024-01-28T00:51:30.672158Z",
     "shell.execute_reply": "2024-01-28T00:51:30.670832Z",
     "shell.execute_reply.started": "2024-01-28T00:51:30.663892Z"
    }
   },
   "outputs": [],
   "source": [
    "FREEZE_EMBEDDINGS = False\n",
    "FREEZE_LAYERS = 0\n",
    "\n",
    "if FREEZE_EMBEDDINGS:\n",
    "    print(\"Freezing embeddings.\")\n",
    "    for param in model.deberta.embeddings.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "if FREEZE_LAYERS > 0:\n",
    "    print(f\"Freezing {FREEZE_LAYERS} layers.\")\n",
    "    for layer in model.deberta.encoder.layer[:FREEZE_LAYERS]:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-28T00:51:30.674786Z",
     "iopub.status.busy": "2024-01-28T00:51:30.674043Z",
     "iopub.status.idle": "2024-01-28T00:51:30.708627Z",
     "shell.execute_reply": "2024-01-28T00:51:30.706766Z",
     "shell.execute_reply.started": "2024-01-28T00:51:30.674738Z"
    }
   },
   "outputs": [],
   "source": [
    "final_ds = ds.train_test_split(test_size=0.30, seed=42)\n",
    "final_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 因为这里我们的分割导致train里面包含所有标签，我们将train作为实际的test，test作为实际的train。(如果是五五开，seed=48的话)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-28T00:51:30.711185Z",
     "iopub.status.busy": "2024-01-28T00:51:30.710696Z",
     "iopub.status.idle": "2024-01-28T00:51:33.595977Z",
     "shell.execute_reply": "2024-01-28T00:51:33.595086Z",
     "shell.execute_reply.started": "2024-01-28T00:51:30.711142Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = final_ds[\"train\"].to_pandas()\n",
    "have_label = 0\n",
    "no_label = 0\n",
    "label_dict = {}\n",
    "for idx, row in tqdm(train_ds.iterrows(), total=len(train_ds)):\n",
    "    labels = row[\"provided_labels\"].tolist()\n",
    "    all_labels_are_O = all(label == \"O\" for label in labels)\n",
    "    if all_labels_are_O:\n",
    "        no_label += 1\n",
    "    else:\n",
    "        have_label += 1\n",
    "    for label in labels:\n",
    "        if label in label_dict:\n",
    "            label_dict[label] += 1\n",
    "        else:\n",
    "            label_dict[label] = 1\n",
    "\n",
    "sorted_keys = sorted(label_dict.keys())\n",
    "for key in sorted_keys:\n",
    "    print(f\"{key}: {label_dict[key]}\")\n",
    "\n",
    "print(\"Number of examples with no label:\", no_label)\n",
    "print(\"Number of examples with labels:\", have_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-28T00:51:33.597956Z",
     "iopub.status.busy": "2024-01-28T00:51:33.597545Z",
     "iopub.status.idle": "2024-01-28T00:51:36.864700Z",
     "shell.execute_reply": "2024-01-28T00:51:36.863481Z",
     "shell.execute_reply.started": "2024-01-28T00:51:33.597906Z"
    }
   },
   "outputs": [],
   "source": [
    "test_ds = final_ds[\"test\"].to_pandas()\n",
    "test_ds[\"is_have_label\"] = 0\n",
    "\n",
    "have_label = 0\n",
    "no_label = 0\n",
    "label_dict = {}\n",
    "for idx, row in tqdm(test_ds.iterrows(), total=len(test_ds)):\n",
    "    labels = row[\"provided_labels\"].tolist()\n",
    "    all_labels_are_O = all(label == \"O\" for label in labels)\n",
    "    if all_labels_are_O:\n",
    "        no_label += 1\n",
    "        test_ds.at[idx, \"is_have_label\"] = 0\n",
    "    else:\n",
    "        have_label += 1\n",
    "        test_ds.at[idx, \"is_have_label\"] = 1\n",
    "    for label in labels:\n",
    "        if label in label_dict:\n",
    "            label_dict[label] += 1\n",
    "        else:\n",
    "            label_dict[label] = 1\n",
    "\n",
    "sorted_keys = sorted(label_dict.keys())\n",
    "for key in sorted_keys:\n",
    "    print(f\"{key}: {label_dict[key]}\")\n",
    "\n",
    "print(\"Number of examples with no label:\", no_label)\n",
    "print(\"Number of examples with labels:\", have_label)\n",
    "\n",
    "test_ds1 = test_ds[test_ds[\"is_have_label\"] == 1]\n",
    "print(test_ds1.shape)\n",
    "test_ds0 = test_ds[test_ds[\"is_have_label\"] == 0]\n",
    "print(test_ds0.shape)\n",
    "test_ds0 = test_ds0.sample(int(1 * len(test_ds1)))\n",
    "test_ds = pd.concat([test_ds0, test_ds1])\n",
    "\n",
    "test_ds.drop(columns=[\"is_have_label\"], inplace=True)\n",
    "test_ds.reset_index(drop=True, inplace=True)\n",
    "print(\"Final shape of test_ds:\", test_ds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 额外的数据集不作为validation，只用作训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-28T00:51:36.866586Z",
     "iopub.status.busy": "2024-01-28T00:51:36.866239Z",
     "iopub.status.idle": "2024-01-28T00:53:03.982631Z",
     "shell.execute_reply": "2024-01-28T00:53:03.981138Z",
     "shell.execute_reply.started": "2024-01-28T00:51:36.866553Z"
    }
   },
   "outputs": [],
   "source": [
    "extra_data = json.load(open(\"../kaggle_dataset/pjm_gpt_2k_0126_fixed.json\"))\n",
    "extra_ds = Dataset.from_dict({\n",
    "    \"full_text\": [x[\"full_text\"] for x in extra_data],\n",
    "    \"document\": [str(x[\"document\"]) for x in extra_data],\n",
    "    \"tokens\": [x[\"tokens\"] for x in extra_data],\n",
    "    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in extra_data],\n",
    "    \"provided_labels\": [x[\"labels\"] for x in extra_data],\n",
    "})\n",
    "extra_ds = extra_ds.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer, \"label2id\": label2id}, num_proc=2)\n",
    "extra_ds = extra_ds.class_encode_column(\"group\")\n",
    "print(extra_ds)\n",
    "extra_ds = extra_ds.to_pandas()\n",
    "\n",
    "train_ds = pd.concat([train_ds, extra_ds])\n",
    "train_ds = train_ds.sample(len(train_ds), random_state=42)\n",
    "train_ds.reset_index(drop=True, inplace=True)\n",
    "print(train_ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-28T00:53:03.985637Z",
     "iopub.status.busy": "2024-01-28T00:53:03.984853Z",
     "iopub.status.idle": "2024-01-28T00:53:06.636980Z",
     "shell.execute_reply": "2024-01-28T00:53:06.635502Z",
     "shell.execute_reply.started": "2024-01-28T00:53:03.985586Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_ds)\n",
    "test_dataset = Dataset.from_pandas(test_ds)\n",
    "\n",
    "final_ds = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "print(final_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-28T00:53:06.638810Z",
     "iopub.status.busy": "2024-01-28T00:53:06.638455Z",
     "iopub.status.idle": "2024-01-28T00:53:08.193862Z",
     "shell.execute_reply": "2024-01-28T00:53:08.191833Z",
     "shell.execute_reply.started": "2024-01-28T00:53:06.638772Z"
    }
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    fp16=True,\n",
    "    warmup_steps=25,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    report_to=\"none\",\n",
    "    gradient_accumulation_steps=16,\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    save_total_limit=6,\n",
    "    overwrite_output_dir=True,\n",
    "    load_best_model_at_end=True,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    weight_decay=0.001\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=final_ds[\"train\"],\n",
    "    eval_dataset=final_ds[\"test\"],\n",
    "    data_collator=collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=partial(compute_metrics, all_labels=all_labels),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-28T00:53:08.195382Z",
     "iopub.status.idle": "2024-01-28T00:53:08.196785Z",
     "shell.execute_reply": "2024-01-28T00:53:08.196543Z",
     "shell.execute_reply.started": "2024-01-28T00:53:08.196512Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-28T00:53:08.198200Z",
     "iopub.status.idle": "2024-01-28T00:53:08.199307Z",
     "shell.execute_reply": "2024-01-28T00:53:08.199076Z",
     "shell.execute_reply.started": "2024-01-28T00:53:08.199048Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"final\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-28T00:53:08.200996Z",
     "iopub.status.idle": "2024-01-28T00:53:08.201744Z",
     "shell.execute_reply": "2024-01-28T00:53:08.201505Z",
     "shell.execute_reply.started": "2024-01-28T00:53:08.201479Z"
    }
   },
   "outputs": [],
   "source": [
    "def delete_optimizer_files(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file == \"optimizer.pt\":\n",
    "                os.remove(os.path.join(root, file))\n",
    "                print(f\"Deleted: {os.path.join(root, file)}\")\n",
    "\n",
    "directory_path = \"/kaggle/working/\"\n",
    "delete_optimizer_files(directory_path)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    },
    {
     "datasetId": 2210196,
     "sourceId": 3693646,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3958554,
     "sourceId": 6890859,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4353252,
     "sourceId": 7490668,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
