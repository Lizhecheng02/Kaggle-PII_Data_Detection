{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\86183\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['(', 'hkasfh112121', ')', ','], 'trailing_whitespace': [True, True, False, False]}\n"
     ]
    }
   ],
   "source": [
    "en_tokenizer = English().tokenizer\n",
    "\n",
    "def tokenize_with_spacy(text, tokenizer=en_tokenizer):\n",
    "    tokenized_text = tokenizer(text)\n",
    "    tokens = [token.text for token in tokenized_text]\n",
    "    trailing_whitespace = [bool(token.whitespace_) for token in tokenized_text]\n",
    "    return {'tokens': tokens, 'trailing_whitespace': trailing_whitespace}\n",
    "\n",
    "print(tokenize_with_spacy(\"( hkasfh112121 ),\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pj_0</td>\n",
       "      <td>As I sat down to tackle the complex challenge ...</td>\n",
       "      <td>[As, I, sat, down, to, tackle, the, complex, c...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pj_1</td>\n",
       "      <td>In the fast-paced world we live in today, it i...</td>\n",
       "      <td>[In, the, fast, -, paced, world, we, live, in,...</td>\n",
       "      <td>[True, True, False, False, True, True, True, T...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pj_2</td>\n",
       "      <td>In the realm of problem-solving, the ability t...</td>\n",
       "      <td>[In, the, realm, of, problem, -, solving, ,, t...</td>\n",
       "      <td>[True, True, True, True, False, False, False, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  document                                          full_text  \\\n",
       "0     pj_0  As I sat down to tackle the complex challenge ...   \n",
       "1     pj_1  In the fast-paced world we live in today, it i...   \n",
       "2     pj_2  In the realm of problem-solving, the ability t...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [As, I, sat, down, to, tackle, the, complex, c...   \n",
       "1  [In, the, fast, -, paced, world, we, live, in,...   \n",
       "2  [In, the, realm, of, problem, -, solving, ,, t...   \n",
       "\n",
       "                                 trailing_whitespace  \\\n",
       "0  [True, True, True, True, True, True, True, Tru...   \n",
       "1  [True, True, False, False, True, True, True, T...   \n",
       "2  [True, True, True, True, False, False, False, ...   \n",
       "\n",
       "                                              labels  \n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"../kaggle_notebook/more_data.json\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_df = pd.DataFrame(columns=[\"document\", \"full_text\", \"tokens\", \"trailing_whitespace\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 89.43it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    if len(row[\"tokens\"]) != len(row[\"trailing_whitespace\"]) or len(row[\"trailing_whitespace\"]) != len(row[\"labels\"]):\n",
    "        print(\"The lengths of different columns are not equal!\")\n",
    "    else:\n",
    "        new_tokens = []\n",
    "        new_trailing_whitespace = []\n",
    "        new_labels = []\n",
    "        new_full_text = \"\"\n",
    "\n",
    "        label_lists = [\"B-USERNAME\", \"B-ID_NUM\", \"B-EMAIL\", \"B-URL_PERSONAL\"]\n",
    "\n",
    "        total_len = len(row[\"tokens\"])\n",
    "        for i in range(total_len):\n",
    "            if row[\"labels\"][i] not in label_lists:\n",
    "                new_tokens.append(row[\"tokens\"][i])\n",
    "                new_trailing_whitespace.append(row[\"trailing_whitespace\"][i])\n",
    "                new_labels.append(row[\"labels\"][i])\n",
    "            else:\n",
    "                if i + 1 < total_len and row[\"labels\"][i + 1] != \"O\":\n",
    "                    new_tokens.append(row[\"tokens\"][i])\n",
    "                    new_trailing_whitespace.append(\n",
    "                        row[\"trailing_whitespace\"][i])\n",
    "                    new_labels.append(row[\"labels\"][i])\n",
    "                elif i + 1 < total_len and row[\"labels\"][i + 1] == \"O\":\n",
    "                    random_float = random.uniform(0, 1)\n",
    "                    if random_float <= 0.01:  # 这里我们左右加括号并且留一个空格\n",
    "                        new_tokens.extend([\"(\", row[\"tokens\"][i], \")\"])\n",
    "                        new_trailing_whitespace.extend([True, True, row[\"trailing_whitespace\"][i]])\n",
    "                        new_labels.extend([\"O\", row[\"labels\"][i], \"O\"])\n",
    "                    elif random_float <= 0.03:  # 这里我们左右加括号但是不留空格\n",
    "                        new_tokens.extend([\"(\", row[\"tokens\"][i], \")\"])\n",
    "                        new_trailing_whitespace.extend([False, False, row[\"trailing_whitespace\"][i]])\n",
    "                        new_labels.extend([\"O\", row[\"labels\"][i], \"O\"])\n",
    "\n",
    "        new_full_text = \"\".join([token + \" \" * space for token, space in zip(new_tokens, new_trailing_whitespace)])\n",
    "\n",
    "        if len(new_tokens) != len(new_trailing_whitespace) or len(new_trailing_whitespace) != len(new_labels):\n",
    "            print(\"The lengths of different columns are not equal!\")\n",
    "\n",
    "        new_row = pd.DataFrame({\n",
    "            \"document\": [row[\"document\"]],\n",
    "            \"full_text\": [new_full_text],\n",
    "            \"tokens\": [list(new_tokens)],\n",
    "            \"trailing_whitespace\": [list(new_trailing_whitespace)],\n",
    "            \"labels\": [list(new_labels)]\n",
    "        })\n",
    "        aug_df = pd.concat([aug_df, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_df.to_json(\"augmented_data.json\", orient=\"records\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
