{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tokenizer = English().tokenizer\n",
    "\n",
    "def tokenize_with_spacy(text, tokenizer=en_tokenizer):\n",
    "    tokenized_text = tokenizer(text)\n",
    "    tokens = [token.text for token in tokenized_text]\n",
    "    trailing_whitespace = [bool(token.whitespace_) for token in tokenized_text]\n",
    "    return {\"tokens\": tokens, \"trailing_whitespace\": trailing_whitespace}\n",
    "\n",
    "print(tokenize_with_spacy(\"http://www.youtube.com/lizhecheng/hdkahdkahdikagk4784279hdkadhdsadadadaXilfshfl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"./lzc_persuade_2.0_based.json\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_df = pd.DataFrame(columns=[\"document\", \"full_text\", \"tokens\", \"trailing_whitespace\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    if len(row[\"tokens\"]) != len(row[\"trailing_whitespace\"]) or len(row[\"trailing_whitespace\"]) != len(row[\"labels\"]):\n",
    "        print(\"The lengths of different columns are not equal!\")\n",
    "    else:\n",
    "        new_tokens = []\n",
    "        new_trailing_whitespace = []\n",
    "        new_labels = []\n",
    "        new_full_text = \"\"\n",
    "\n",
    "        label_lists = [\"B-USERNAME\", \"B-ID_NUM\", \"B-EMAIL\", \"B-URL_PERSONAL\"]\n",
    "\n",
    "        total_len = len(row[\"tokens\"])\n",
    "        for i in range(total_len):\n",
    "            if row[\"labels\"][i] not in label_lists:\n",
    "                new_tokens.append(row[\"tokens\"][i])\n",
    "                new_trailing_whitespace.append(row[\"trailing_whitespace\"][i])\n",
    "                new_labels.append(row[\"labels\"][i])\n",
    "            else:\n",
    "                if i + 1 < total_len and row[\"labels\"][i + 1] != \"O\":\n",
    "                    new_tokens.append(row[\"tokens\"][i])\n",
    "                    new_trailing_whitespace.append(\n",
    "                        row[\"trailing_whitespace\"][i])\n",
    "                    new_labels.append(row[\"labels\"][i])\n",
    "                elif i + 1 < total_len and row[\"labels\"][i + 1] == \"O\":\n",
    "                    random_float = random.uniform(0, 1)\n",
    "                    if random_float <= 0.01:  # 这里我们左右加括号并且留一个空格\n",
    "                        new_tokens.extend([\"(\", row[\"tokens\"][i], \")\"])\n",
    "                        new_trailing_whitespace.extend([True, True, row[\"trailing_whitespace\"][i]])\n",
    "                        new_labels.extend([\"O\", row[\"labels\"][i], \"O\"])\n",
    "                    elif random_float <= 0.03:  # 这里我们左右加括号但是不留空格\n",
    "                        new_tokens.extend([\"(\", row[\"tokens\"][i], \")\"])\n",
    "                        new_trailing_whitespace.extend([False, False, row[\"trailing_whitespace\"][i]])\n",
    "                        new_labels.extend([\"O\", row[\"labels\"][i], \"O\"])\n",
    "\n",
    "        new_full_text = \"\".join([token + \" \" * space for token, space in zip(new_tokens, new_trailing_whitespace)])\n",
    "\n",
    "        if len(new_tokens) != len(new_trailing_whitespace) or len(new_trailing_whitespace) != len(new_labels):\n",
    "            print(\"The lengths of different columns are not equal!\")\n",
    "\n",
    "        new_row = pd.DataFrame({\n",
    "            \"document\": [row[\"document\"]],\n",
    "            \"full_text\": [new_full_text],\n",
    "            \"tokens\": [list(new_tokens)],\n",
    "            \"trailing_whitespace\": [list(new_trailing_whitespace)],\n",
    "            \"labels\": [list(new_labels)]\n",
    "        })\n",
    "        aug_df = pd.concat([aug_df, new_row], ignore_index=True)\n",
    "\n",
    "aug_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_df.to_json(\"lzc_persuade_2.0_based_augmented.json\", orient=\"records\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
