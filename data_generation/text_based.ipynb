{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import time \n",
    "import spacy\n",
    "\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../kaggle_dataset/train_split.json\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_O(labels):\n",
    "    is_all_O = all(label == 'O' for label in labels)\n",
    "    return is_all_O\n",
    "\n",
    "df['is_all_O'] = df['labels'].apply(all_O)\n",
    "df = df[df['is_all_O'] == 0]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = ''\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model_input, idx):\n",
    "    messages = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': model_input\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    random_temperature = random.uniform(0.0, 1.0)\n",
    "    random_top_p = random.uniform(0.5, 1.0)\n",
    "\n",
    "    flag = False\n",
    "\n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model='gpt-3.5-turbo-16k',\n",
    "                messages=messages,\n",
    "                max_tokens=4096,\n",
    "                frequency_penalty=1.12,\n",
    "                temperature=random_temperature,\n",
    "                top_p=random_top_p\n",
    "            )\n",
    "            output = response.choices[0].message.content\n",
    "            flag = True\n",
    "            print(f'Generated Successfully on Idx-{idx}!!!')\n",
    "            return output\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f'Attempt {attempt + 1} on Idx-{idx} Failed: {e}')\n",
    "            time.sleep(1)\n",
    "\n",
    "    if flag == False:\n",
    "        print(f'Idx-{idx} Failed at Last')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label(model_input, idx):\n",
    "    messages = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': model_input\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    flag = False\n",
    "\n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model='gpt-3.5-turbo-16k',\n",
    "                messages=messages,\n",
    "                max_tokens=512,\n",
    "                frequency_penalty=1.12,\n",
    "                temperature=0.0,\n",
    "                top_p=0.95\n",
    "            )\n",
    "            output = response.choices[0].message.content\n",
    "            flag = True\n",
    "            print(f'Generated Successfully on Idx-{idx}!!!')\n",
    "            return output\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f'Attempt {attempt + 1} on Idx-{idx} Failed: {e}')\n",
    "            time.sleep(1)\n",
    "\n",
    "    if flag == False:\n",
    "        print(f'Idx-{idx} Failed at Last')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(original_list, chunk_size=64):\n",
    "    for i in range(0, len(original_list), chunk_size):\n",
    "        yield original_list[i:min(i + chunk_size, len(original_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    original_text = row['full_text']\n",
    "    model_input_for_new_text_generation = \"Rewrite the following article, completely altering its structure, but do not change the details and main idea of the article. You only need to return the text you have written.\\n\\n\" + original_text\n",
    "    new_text = generate_text(model_input=model_input_for_new_text_generation, idx=idx)\n",
    "    new_text = new_text.strip()\n",
    "    print(new_text)\n",
    "    \n",
    "    nlp = spacy.blank('en')\n",
    "    doc = nlp(new_text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    \n",
    "    split_token_lists = list(split_list(original_list=tokens))\n",
    "    for i in range(len(split_token_lists)):\n",
    "        prompt = (\n",
    "            \"It is known that there are currently seven main types of PII (Personally Identifiable Information): \\n\"\n",
    "            \"(1)NAME_STUDENT - The full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names. \\n\"\n",
    "            \"(2)EMAIL - A studentâ€™s email address. \\n\"\n",
    "            \"(3)USERNAME - A student's username on any platform. \\n\"\n",
    "            \"(4)ID_NUM - A number or sequence of characters that could be used to identify a student, such as a student ID or a social security number. \\n\"\n",
    "            \"(5)PHONE_NUM - A phone number associated with a student. \\n\"\n",
    "            \"(6)URL_PERSONAL - A URL that might be used to identify a student. \\n\"\n",
    "            \"(7)STREET_ADDRESS - A full or partial street address that is associated with the student, such as their home address. \\n\\n\"\n",
    "\n",
    "            \"At the same time,token labels are presented in BIO (Beginning, Inner, Outer) format. The PII type is prefixed with 'B-' when it is the beginning of an entity. If the token is a continuation of an entity, it is prefixed with 'I-'. Tokens that are not PII are labeled 'O', which means labels are like 'B-NAME_STUDENT', 'I-USERNAME'. \\n\"\n",
    "            \"Thus, we have 15 kinds of labels in total, they are: 'B-EMAIL', 'B-ID_NUM', 'B-NAME_STUDENT', 'B-PHONE_NUM', 'B-STREET_ADDRESS', 'B-URL_PERSONAL', 'B-USERNAME', 'I-EMAIL', 'I-ID_NUM', 'I-NAME_STUDENT', 'I-PHONE_NUM', 'I-STREET_ADDRESS', 'I-URL_PERSONAL', 'I-USERNAME', 'O'. \\n\\n\"\n",
    "\n",
    "            \"Here is an example: \\n\"\n",
    "            \"token list: ['Design','Thinking','for','innovation','reflexion','-','Avril','2021','-','Nathalie','Sylla','\\\\n\\\\n','Challenge','&','selection','\\\\n\\\\n','The','tool','I','use','to','help','all','stakeholders','finding','their','way','through','the','complexity','of','a','project','is','the','','mind','map','.','\\\\n\\\\n','What','exactly','is','a','mind','map','?'] \\n\"\n",
    "            \"label list: ['O','O','O','O','O','O','O','O','O','B-NAME_STUDENT','I-NAME_STUDENT','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O','O'] \\n\\n\"\n",
    "\n",
    "            \"Now you should label the following token list for me and return a complete list of labels just like token list format. Don't be lazy and don't include any extra information. Do not include any labels other than the 15 types mentioned above. \\n\"\n",
    "            \"token list: \"\n",
    "        )\n",
    "        print(str(split_token_lists[i]))\n",
    "        model_input_for_label_generation = prompt + str(split_token_lists[i]) + '\\n' + 'label list: '\n",
    "        print(model_input_for_label_generation)\n",
    "        labels = generate_label(model_input_for_label_generation, idx=i)\n",
    "        print(labels)\n",
    "        \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
