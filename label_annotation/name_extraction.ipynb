{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = pd.read_json(\"../kaggle_dataset/train_split.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(text):\n",
    "\n",
    "    start_prompt = \"\"\"\n",
    "Assuming you are an expert in extracting various person names from the given text. Now I will provide you with an essay that may contains person names. You must find all of them and return to me. \\n\n",
    "    \"\"\"\n",
    "\n",
    "    end_prompt = \"\"\"\n",
    "You only need to return the person names. If there are repeated names, you only need to return them once, separated names by commas. If the essay contains no person names, return None.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": start_prompt + text + \"\\n\" + end_prompt\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    client = openai.OpenAI()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=messages,\n",
    "        temperature=0.0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv = pd.DataFrame(columns=[\"id\", \"name_list\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/4761 [00:11<15:48:16, 11.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/4761 [00:13<7:19:47,  5.54s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/4761 [00:13<9:04:09,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, row in tqdm(original_dataset.iterrows(), total=len(original_dataset)):\n",
    "    text = row[\"full_text\"]\n",
    "    namelist = get_name(text)\n",
    "    print(namelist)\n",
    "\n",
    "    new_row = pd.DataFrame({\n",
    "        \"id\": [idx],\n",
    "        \"name_list\": [list(namelist)]\n",
    "    })\n",
    "\n",
    "    output_csv = pd.concat([output_csv, new_row], ignore_index=True)\n",
    "    output_csv.to_csv(\"all_names.csv\", index=False)\n",
    "    if idx == 2:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
