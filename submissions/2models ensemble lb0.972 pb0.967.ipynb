{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3951d002",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-09T21:11:02.888176Z",
     "iopub.status.busy": "2024-03-09T21:11:02.887620Z",
     "iopub.status.idle": "2024-03-09T21:11:33.192529Z",
     "shell.execute_reply": "2024-03-09T21:11:33.191778Z"
    },
    "papermill": {
     "duration": 30.316778,
     "end_time": "2024-03-09T21:11:33.194842",
     "exception": false,
     "start_time": "2024-03-09T21:11:02.878064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import argparse\n",
    "import os\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification, LongformerTokenizerFast\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8052be01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:11:33.239651Z",
     "iopub.status.busy": "2024-03-09T21:11:33.239382Z",
     "iopub.status.idle": "2024-03-09T21:11:33.243294Z",
     "shell.execute_reply": "2024-03-09T21:11:33.242491Z"
    },
    "papermill": {
     "duration": 0.016296,
     "end_time": "2024-03-09T21:11:33.246179",
     "exception": false,
     "start_time": "2024-03-09T21:11:33.229883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INFERENCE_MAX_LENGTH = [1024, 1536]\n",
    "INFERENCE_STRIDE = 256\n",
    "TRAINING_MODEL_PATH = [\n",
    "    '/kaggle/input/pii-data-detection-models/checkpoint-900',\n",
    "    '/kaggle/input/full-model/pious-sweep-3/checkpoint-2900'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bf0c663",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:11:33.264740Z",
     "iopub.status.busy": "2024-03-09T21:11:33.264442Z",
     "iopub.status.idle": "2024-03-09T21:11:33.271446Z",
     "shell.execute_reply": "2024-03-09T21:11:33.270507Z"
    },
    "papermill": {
     "duration": 0.018402,
     "end_time": "2024-03-09T21:11:33.273421",
     "exception": false,
     "start_time": "2024-03-09T21:11:33.255019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    0: 'B-EMAIL',\n",
    "    1: 'B-ID_NUM',\n",
    "    2: 'B-NAME_STUDENT',\n",
    "    3: 'B-PHONE_NUM',\n",
    "    4: 'B-STREET_ADDRESS',\n",
    "    5: 'B-URL_PERSONAL',\n",
    "    6: 'B-USERNAME',\n",
    "    7: 'I-ID_NUM',\n",
    "    8: 'I-NAME_STUDENT',\n",
    "    9: 'I-PHONE_NUM',\n",
    "    10: 'I-STREET_ADDRESS',\n",
    "    11: 'I-URL_PERSONAL',\n",
    "    12: 'O'\n",
    "}\n",
    "label2id = {\n",
    "    'B-EMAIL': 0,\n",
    "    'B-ID_NUM': 1,\n",
    "    'B-NAME_STUDENT': 2,\n",
    "    'B-PHONE_NUM': 3,\n",
    "    'B-STREET_ADDRESS': 4,\n",
    "    'B-URL_PERSONAL': 5,\n",
    "    'B-USERNAME': 6,\n",
    "    'I-ID_NUM': 7,\n",
    "    'I-NAME_STUDENT': 8,\n",
    "    'I-PHONE_NUM': 9,\n",
    "    'I-STREET_ADDRESS': 10,\n",
    "    'I-URL_PERSONAL': 11,\n",
    "    'O': 12\n",
    "}\n",
    "all_labels = [\n",
    "    'B-EMAIL',\n",
    "    'B-ID_NUM',\n",
    "    'B-NAME_STUDENT',\n",
    "    'B-PHONE_NUM',\n",
    "    'B-STREET_ADDRESS',\n",
    "    'B-URL_PERSONAL',\n",
    "    'B-USERNAME',\n",
    "    'I-ID_NUM',\n",
    "    'I-NAME_STUDENT',\n",
    "    'I-PHONE_NUM',\n",
    "    'I-STREET_ADDRESS',\n",
    "    'I-URL_PERSONAL',\n",
    "    'O'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac429e97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:11:33.293415Z",
     "iopub.status.busy": "2024-03-09T21:11:33.292768Z",
     "iopub.status.idle": "2024-03-09T21:11:33.338708Z",
     "shell.execute_reply": "2024-03-09T21:11:33.337938Z"
    },
    "papermill": {
     "duration": 0.058197,
     "end_time": "2024-03-09T21:11:33.340629",
     "exception": false,
     "start_time": "2024-03-09T21:11:33.282432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(\"/kaggle/input/pii-detection-removal-from-educational-data/test.json\")\n",
    "\n",
    "\n",
    "def get_labels(word_ids, word_labels):\n",
    "    label_ids = []\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            label_ids.append(-100)\n",
    "        else:\n",
    "            label_ids.append(label2id[word_labels[word_idx]])\n",
    "    return label_ids\n",
    "\n",
    "# Tokenize texts, possibly generating more than one tokenized sample for each text\n",
    "\n",
    "\n",
    "def tokenize(df, inference_max_length, to_tensor=True, with_labels=True):\n",
    "\n",
    "    # This is what's different from a longformer\n",
    "    # Read the parameters with attention\n",
    "    encoded = tokenizer(df['tokens'].tolist(),\n",
    "                        is_split_into_words=True,\n",
    "                        return_overflowing_tokens=True,\n",
    "                        stride=INFERENCE_STRIDE,\n",
    "                        max_length=inference_max_length,\n",
    "                        padding=\"max_length\",\n",
    "                        truncation=True)\n",
    "\n",
    "    if with_labels:\n",
    "        encoded['labels'] = []\n",
    "\n",
    "    encoded['wids'] = []\n",
    "    n = len(encoded['overflow_to_sample_mapping'])\n",
    "    for i in range(n):\n",
    "\n",
    "        # Map back to original row\n",
    "        text_idx = encoded['overflow_to_sample_mapping'][i]\n",
    "\n",
    "        # Get word indexes (this is a global index that takes into consideration the chunking :D )\n",
    "        word_ids = encoded.word_ids(i)\n",
    "\n",
    "        if with_labels:\n",
    "            # Get word labels of the full un-chunked text\n",
    "            word_labels = df['labels'].iloc[text_idx]\n",
    "\n",
    "            # Get the labels associated with the word indexes\n",
    "            label_ids = get_labels(word_ids, word_labels)\n",
    "            encoded['labels'].append(label_ids)\n",
    "        encoded['wids'].append([w if w is not None else -1 for w in word_ids])\n",
    "\n",
    "    if to_tensor:\n",
    "        encoded = {key: torch.as_tensor(val) for key, val in encoded.items()}\n",
    "    return encoded\n",
    "\n",
    "\n",
    "class PIIDataset(Dataset):\n",
    "    def __init__(self, tokenized_ds):\n",
    "        self.data = tokenized_ds\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = {k: self.data[k][index] for k in self.data.keys()}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18af2f2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:11:33.360089Z",
     "iopub.status.busy": "2024-03-09T21:11:33.359847Z",
     "iopub.status.idle": "2024-03-09T21:11:33.368257Z",
     "shell.execute_reply": "2024-03-09T21:11:33.367475Z"
    },
    "papermill": {
     "duration": 0.019822,
     "end_time": "2024-03-09T21:11:33.370234",
     "exception": false,
     "start_time": "2024-03-09T21:11:33.350412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inferenceV3(df, dl, thres=0.9):\n",
    "\n",
    "    # These 2 dictionaries will hold text-level data\n",
    "    # Helping in the merging process by accumulating data\n",
    "    # Through all the chunks\n",
    "\n",
    "    token_pred = defaultdict(lambda: defaultdict(int))\n",
    "    seen_words_idx = defaultdict(set)\n",
    "\n",
    "    for batch in tqdm(dl):\n",
    "        ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "        mask = batch[\"attention_mask\"].to(\"cuda\")\n",
    "        preds = model(ids, attention_mask=mask, return_dict=False)[0].cpu().detach().numpy()\n",
    "        preds_softmax = np.exp(preds) / np.sum(np.exp(preds), axis=2).reshape(preds.shape[0], preds.shape[1], 1)\n",
    "\n",
    "        del ids, mask\n",
    "\n",
    "        # Go over each prediction, getting the text_id reference\n",
    "\n",
    "        for k, (chunk_preds, text_id) in enumerate(zip(preds_softmax, batch['overflow_to_sample_mapping'].tolist())):\n",
    "            # The word_ids are absolute references in the original text\n",
    "            word_ids = batch['wids'][k].numpy()\n",
    "\n",
    "            for idx, word_idx in enumerate(word_ids):\n",
    "                if word_idx != -1 and word_idx not in seen_words_idx[text_id]:\n",
    "                    token_pred[text_id][word_idx] += chunk_preds[idx]\n",
    "                    seen_words_idx[text_id].add(word_idx)\n",
    "    return token_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d418cb76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:11:33.390298Z",
     "iopub.status.busy": "2024-03-09T21:11:33.389946Z",
     "iopub.status.idle": "2024-03-09T21:11:33.400127Z",
     "shell.execute_reply": "2024-03-09T21:11:33.399172Z"
    },
    "papermill": {
     "duration": 0.022801,
     "end_time": "2024-03-09T21:11:33.402320",
     "exception": false,
     "start_time": "2024-03-09T21:11:33.379519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inferenceV4(df, dl):\n",
    "\n",
    "    # These 2 dictionaries will hold text-level data\n",
    "    # Helping in the merging process by accumulating data\n",
    "    # Through all the chunks\n",
    "\n",
    "    token_pred = defaultdict(lambda: defaultdict(int))\n",
    "    token_cnt = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for batch in tqdm(dl):\n",
    "        ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "        mask = batch[\"attention_mask\"].to(\"cuda\")\n",
    "        preds = model(ids, attention_mask=mask, return_dict=False)[0].cpu().detach().numpy()\n",
    "        preds_softmax = np.exp(preds) / np.sum(np.exp(preds), axis=2).reshape(preds.shape[0], preds.shape[1], 1)\n",
    "\n",
    "        del ids, mask\n",
    "\n",
    "        # Go over each prediction, getting the text_id reference\n",
    "\n",
    "        for k, (chunk_preds, text_id) in enumerate(zip(preds_softmax, batch['overflow_to_sample_mapping'].tolist())):\n",
    "            # The word_ids are absolute references in the original text\n",
    "            word_ids = batch['wids'][k].numpy()\n",
    "\n",
    "            for idx, word_idx in enumerate(word_ids):\n",
    "                if word_idx != -1:\n",
    "                    token_pred[text_id][word_idx] += chunk_preds[idx]\n",
    "                    token_cnt[text_id][word_idx] += 1\n",
    "\n",
    "    for text_id in token_pred:\n",
    "        for word_idx in token_pred[text_id]:\n",
    "            token_pred[text_id][word_idx] /= token_cnt[text_id][word_idx]\n",
    "\n",
    "    return token_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02d25c01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:11:33.424984Z",
     "iopub.status.busy": "2024-03-09T21:11:33.424282Z",
     "iopub.status.idle": "2024-03-09T21:11:33.436588Z",
     "shell.execute_reply": "2024-03-09T21:11:33.435673Z"
    },
    "papermill": {
     "duration": 0.02628,
     "end_time": "2024-03-09T21:11:33.438767",
     "exception": false,
     "start_time": "2024-03-09T21:11:33.412487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inferenceV5(df, dl):\n",
    "\n",
    "    # These 2 dictionaries will hold text-level data\n",
    "    # Helping in the merging process by accumulating data\n",
    "    # Through all the chunks\n",
    "\n",
    "    token_pred = defaultdict(lambda: defaultdict(int))\n",
    "    token_cnt = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for batch in tqdm(dl):\n",
    "        ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "        mask = batch[\"attention_mask\"].to(\"cuda\")\n",
    "        preds = model(ids, attention_mask=mask, return_dict=False)[0].cpu().detach().numpy()\n",
    "        preds_softmax = np.exp(preds) / np.sum(np.exp(preds), axis=2).reshape(preds.shape[0], preds.shape[1], 1)\n",
    "\n",
    "        del ids, mask\n",
    "\n",
    "        # Go over each prediction, getting the text_id reference\n",
    "        seen_words_idx = set()\n",
    "        for k, (chunk_preds, text_id) in enumerate(zip(preds_softmax, batch['overflow_to_sample_mapping'].tolist())):\n",
    "            # The word_ids are absolute references in the original text\n",
    "            word_ids = batch['wids'][k].numpy()\n",
    "\n",
    "            for idx, word_idx in enumerate(word_ids):\n",
    "                if word_idx != -1 and word_idx not in seen_words_idx:\n",
    "                    seen_words_idx.add(word_idx)\n",
    "                    token_pred[text_id][word_idx] += chunk_preds[idx]\n",
    "                    token_cnt[text_id][word_idx] += 1\n",
    "\n",
    "    for text_id in token_pred:\n",
    "        for word_idx in token_pred[text_id]:\n",
    "            token_pred[text_id][word_idx] /= token_cnt[text_id][word_idx]\n",
    "\n",
    "    return token_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68f4b2cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:11:33.460156Z",
     "iopub.status.busy": "2024-03-09T21:11:33.459789Z",
     "iopub.status.idle": "2024-03-09T21:12:25.103048Z",
     "shell.execute_reply": "2024-03-09T21:12:25.101814Z"
    },
    "papermill": {
     "duration": 51.656807,
     "end_time": "2024-03-09T21:12:25.105566",
     "exception": false,
     "start_time": "2024-03-09T21:11:33.448759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:06<00:00,  1.95it/s]\n",
      "100%|██████████| 11/11 [00:08<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "final_token_pred = defaultdict(lambda: defaultdict(int))\n",
    "for idx, model_path in enumerate(TRAINING_MODEL_PATH):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    tokenized_test = tokenize(df, inference_max_length=INFERENCE_MAX_LENGTH[idx], with_labels=False)\n",
    "\n",
    "    test_dataset = PIIDataset(tokenized_test)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=1)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        model_path,\n",
    "        num_labels=len(all_labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "    model.cuda()\n",
    "    token_pred = inferenceV4(df, test_dataloader)\n",
    "    for text_id in token_pred:\n",
    "        for word_idx in token_pred[text_id]:\n",
    "            final_token_pred[text_id][word_idx] += token_pred[text_id][word_idx] / len(TRAINING_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3f9db7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:12:25.135045Z",
     "iopub.status.busy": "2024-03-09T21:12:25.134050Z",
     "iopub.status.idle": "2024-03-09T21:12:25.199295Z",
     "shell.execute_reply": "2024-03-09T21:12:25.198167Z"
    },
    "papermill": {
     "duration": 0.083783,
     "end_time": "2024-03-09T21:12:25.202833",
     "exception": false,
     "start_time": "2024-03-09T21:12:25.119050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "document, token, label = [], [], []\n",
    "for text_id in final_token_pred:\n",
    "    for word_idx in final_token_pred[text_id]:\n",
    "        pred = final_token_pred[text_id][word_idx].argmax(-1)\n",
    "        pred_without_O = final_token_pred[text_id][word_idx][:12].argmax(-1)\n",
    "        if final_token_pred[text_id][word_idx][12] < 0.55:\n",
    "            final_pred = pred_without_O\n",
    "        else:\n",
    "            final_pred = pred\n",
    "        if id2label[final_pred] != 'O':\n",
    "            document.append(df.loc[text_id, \"document\"])\n",
    "            token.append(word_idx)\n",
    "            label.append(id2label[final_pred])\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"document\": document,\n",
    "    \"token\": token,\n",
    "    \"label\": label\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c708d0dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:12:25.231120Z",
     "iopub.status.busy": "2024-03-09T21:12:25.230770Z",
     "iopub.status.idle": "2024-03-09T21:12:25.236169Z",
     "shell.execute_reply": "2024-03-09T21:12:25.235124Z"
    },
    "papermill": {
     "duration": 0.021503,
     "end_time": "2024-03-09T21:12:25.238356",
     "exception": false,
     "start_time": "2024-03-09T21:12:25.216853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score(row):\n",
    "    doc = row.document\n",
    "    tok = row.token\n",
    "    doc_idx = df.query(\"document == @doc\").index[0]\n",
    "    return token_pred[doc_idx][tok][label2id[row.label]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2684691d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:12:25.266365Z",
     "iopub.status.busy": "2024-03-09T21:12:25.265494Z",
     "iopub.status.idle": "2024-03-09T21:12:25.335724Z",
     "shell.execute_reply": "2024-03-09T21:12:25.334763Z"
    },
    "papermill": {
     "duration": 0.086653,
     "end_time": "2024-03-09T21:12:25.337919",
     "exception": false,
     "start_time": "2024-03-09T21:12:25.251266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_df[\"score\"] = pred_df.apply(lambda x: score(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603bbf6a",
   "metadata": {
    "papermill": {
     "duration": 0.012292,
     "end_time": "2024-03-09T21:12:25.362052",
     "exception": false,
     "start_time": "2024-03-09T21:12:25.349760",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1a15809",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:12:25.389365Z",
     "iopub.status.busy": "2024-03-09T21:12:25.388540Z",
     "iopub.status.idle": "2024-03-09T21:12:25.401801Z",
     "shell.execute_reply": "2024-03-09T21:12:25.400659Z"
    },
    "papermill": {
     "duration": 0.029299,
     "end_time": "2024-03-09T21:12:25.404296",
     "exception": false,
     "start_time": "2024-03-09T21:12:25.374997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[['document', 'tokens']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b777b493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:12:25.432334Z",
     "iopub.status.busy": "2024-03-09T21:12:25.431599Z",
     "iopub.status.idle": "2024-03-09T21:12:25.453476Z",
     "shell.execute_reply": "2024-03-09T21:12:25.452600Z"
    },
    "papermill": {
     "duration": 0.036735,
     "end_time": "2024-03-09T21:12:25.455528",
     "exception": false,
     "start_time": "2024-03-09T21:12:25.418793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.explode(['tokens']).reset_index(drop=True).rename(columns={'tokens': 'token'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2278cfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:12:25.482367Z",
     "iopub.status.busy": "2024-03-09T21:12:25.482003Z",
     "iopub.status.idle": "2024-03-09T21:12:25.493332Z",
     "shell.execute_reply": "2024-03-09T21:12:25.492157Z"
    },
    "papermill": {
     "duration": 0.027625,
     "end_time": "2024-03-09T21:12:25.495590",
     "exception": false,
     "start_time": "2024-03-09T21:12:25.467965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['token_str'] = df['token']\n",
    "df['token'] = df.groupby('document').cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "570591ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:12:25.522617Z",
     "iopub.status.busy": "2024-03-09T21:12:25.521767Z",
     "iopub.status.idle": "2024-03-09T21:12:25.538197Z",
     "shell.execute_reply": "2024-03-09T21:12:25.537062Z"
    },
    "papermill": {
     "duration": 0.032307,
     "end_time": "2024-03-09T21:12:25.540410",
     "exception": false,
     "start_time": "2024-03-09T21:12:25.508103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_pred_df = pd.merge(df, pred_df[['document', 'token', 'label', \"score\"]], on=['document', 'token'], how='left')\n",
    "new_pred_df['label'] = new_pred_df['label'].fillna('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bbff403",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:12:25.565963Z",
     "iopub.status.busy": "2024-03-09T21:12:25.565423Z",
     "iopub.status.idle": "2024-03-09T21:12:25.581287Z",
     "shell.execute_reply": "2024-03-09T21:12:25.580304Z"
    },
    "papermill": {
     "duration": 0.030694,
     "end_time": "2024-03-09T21:12:25.583516",
     "exception": false,
     "start_time": "2024-03-09T21:12:25.552822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pp(new_pred_df):\n",
    "    df = new_pred_df.copy()\n",
    "    i = 0\n",
    "    while i < len(df):\n",
    "        st = i\n",
    "        doc = df.loc[st, \"document\"]\n",
    "        tok = df.loc[st, \"token\"]\n",
    "        pred_tok = df.loc[st, \"label\"]\n",
    "        if pred_tok == 'O':\n",
    "            i += 1\n",
    "            continue\n",
    "        lab = pred_tok.split('-')[1]\n",
    "        cur_doc = doc\n",
    "        cur_lab = lab\n",
    "        last_tok = tok\n",
    "        cur_tok = last_tok\n",
    "        # prefix = []\n",
    "        while i < len(df) and cur_doc == doc and cur_lab == lab and last_tok == cur_tok:\n",
    "            # prefix.append(pred_tok.split('-')[0])\n",
    "            last_tok = cur_tok + 1\n",
    "            i += 1\n",
    "            cur_doc = df.loc[i, \"document\"]\n",
    "            cur_tok = df.loc[i, \"token\"]\n",
    "            if i >= len(df) or df.loc[i, \"label\"] == 'O':\n",
    "                break\n",
    "            cur_lab = df.loc[i, \"label\"].split('-')[1]\n",
    "        # exception\n",
    "        if st - 2 >= 0 and df.loc[st - 2, \"document\"] == df.loc[st, \"document\"] and df.loc[st - 1, \"token_str\"] == '\\n' and df.loc[st - 2, \"label\"] != 'O' and df.loc[st - 2, \"label\"].split('-')[1] == lab:\n",
    "            df.loc[st - 1, \"label\"] = 'I-' + lab\n",
    "            df.loc[st - 1, \"score\"] = 1\n",
    "            for j in range(st, i):\n",
    "                if df.loc[j, \"label\"] != 'I-' + lab:\n",
    "                    df.loc[j, \"score\"] = 1\n",
    "                    df.loc[j, \"label\"] = 'I-' + lab\n",
    "            continue\n",
    "\n",
    "        # fix\n",
    "        for j in range(st, i):\n",
    "            if j == st:\n",
    "                if df.loc[j, \"label\"] != 'B-' + lab:\n",
    "                    df.loc[j, \"score\"] = 1\n",
    "                    df.loc[j, \"label\"] = 'B-' + lab\n",
    "            else:\n",
    "                if df.loc[j, \"label\"] != 'I-' + lab:\n",
    "                    df.loc[j, \"score\"] = 1\n",
    "                    df.loc[j, \"label\"] = 'I-' + lab\n",
    "#         print(df.loc[st:i,:])\n",
    "        if lab == 'NAME_STUDENT' and any(len(item) == 2 and item[0].isupper() and item[1] == \".\" for item in df.loc[st:i-1, 'token_str']):\n",
    "            for j in range(st, i):\n",
    "                df.loc[j, \"score\"] = 0\n",
    "                df.loc[j, \"label\"] = 'O'\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc913c28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:12:25.607133Z",
     "iopub.status.busy": "2024-03-09T21:12:25.606619Z",
     "iopub.status.idle": "2024-03-09T21:12:26.020203Z",
     "shell.execute_reply": "2024-03-09T21:12:26.019304Z"
    },
    "papermill": {
     "duration": 0.427746,
     "end_time": "2024-03-09T21:12:26.022571",
     "exception": false,
     "start_time": "2024-03-09T21:12:25.594825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_pred_df = pp(new_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8719f9b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:12:26.046058Z",
     "iopub.status.busy": "2024-03-09T21:12:26.045800Z",
     "iopub.status.idle": "2024-03-09T21:12:26.064852Z",
     "shell.execute_reply": "2024-03-09T21:12:26.063878Z"
    },
    "papermill": {
     "duration": 0.032652,
     "end_time": "2024-03-09T21:12:26.066711",
     "exception": false,
     "start_time": "2024-03-09T21:12:26.034059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>token_str</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Design</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Thinking</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>for</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>innovation</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>reflexion</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8500</th>\n",
       "      <td>123</td>\n",
       "      <td>1689</td>\n",
       "      <td>(</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8501</th>\n",
       "      <td>123</td>\n",
       "      <td>1690</td>\n",
       "      <td>https://www.melessa.uni-</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8502</th>\n",
       "      <td>123</td>\n",
       "      <td>1691</td>\n",
       "      <td>muenchen.de/team/vorstandssprecher/schmidt/pub...</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8503</th>\n",
       "      <td>123</td>\n",
       "      <td>1692</td>\n",
       "      <td>)</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8504</th>\n",
       "      <td>123</td>\n",
       "      <td>1693</td>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8505 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      document  token                                          token_str  \\\n",
       "0            7      0                                             Design   \n",
       "1            7      1                                           Thinking   \n",
       "2            7      2                                                for   \n",
       "3            7      3                                         innovation   \n",
       "4            7      4                                          reflexion   \n",
       "...        ...    ...                                                ...   \n",
       "8500       123   1689                                                  (   \n",
       "8501       123   1690                           https://www.melessa.uni-   \n",
       "8502       123   1691  muenchen.de/team/vorstandssprecher/schmidt/pub...   \n",
       "8503       123   1692                                                  )   \n",
       "8504       123   1693                                               \\n\\n   \n",
       "\n",
       "     label  score  \n",
       "0        O    NaN  \n",
       "1        O    NaN  \n",
       "2        O    NaN  \n",
       "3        O    NaN  \n",
       "4        O    NaN  \n",
       "...    ...    ...  \n",
       "8500     O    NaN  \n",
       "8501     O    NaN  \n",
       "8502     O    NaN  \n",
       "8503     O    NaN  \n",
       "8504     O    NaN  \n",
       "\n",
       "[8505 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3387f9ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:12:26.090385Z",
     "iopub.status.busy": "2024-03-09T21:12:26.090102Z",
     "iopub.status.idle": "2024-03-09T21:12:26.098626Z",
     "shell.execute_reply": "2024-03-09T21:12:26.097887Z"
    },
    "papermill": {
     "duration": 0.0224,
     "end_time": "2024-03-09T21:12:26.100424",
     "exception": false,
     "start_time": "2024-03-09T21:12:26.078024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_pred_df = new_pred_df.query(\"label != 'O'\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53f1f275",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:12:26.124082Z",
     "iopub.status.busy": "2024-03-09T21:12:26.123805Z",
     "iopub.status.idle": "2024-03-09T21:12:26.128570Z",
     "shell.execute_reply": "2024-03-09T21:12:26.127850Z"
    },
    "papermill": {
     "duration": 0.018918,
     "end_time": "2024-03-09T21:12:26.130550",
     "exception": false,
     "start_time": "2024-03-09T21:12:26.111632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "thresholds = {\n",
    "    'B-EMAIL': 0.99,\n",
    "    'B-ID_NUM': 0.4,\n",
    "    'B-NAME_STUDENT': 0,\n",
    "    'B-PHONE_NUM': 0.99,\n",
    "    'B-STREET_ADDRESS': 0.99,\n",
    "    'B-URL_PERSONAL': 0.99,\n",
    "    'B-USERNAME': 0.8,\n",
    "    'I-ID_NUM': 0.8,\n",
    "    'I-NAME_STUDENT': 0.4,\n",
    "    'I-PHONE_NUM': 0.99,\n",
    "    'I-STREET_ADDRESS': 0.99,\n",
    "    'I-URL_PERSONAL': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "601d4d66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:12:26.253689Z",
     "iopub.status.busy": "2024-03-09T21:12:26.253388Z",
     "iopub.status.idle": "2024-03-09T21:12:26.261102Z",
     "shell.execute_reply": "2024-03-09T21:12:26.260297Z"
    },
    "papermill": {
     "duration": 0.021829,
     "end_time": "2024-03-09T21:12:26.263079",
     "exception": false,
     "start_time": "2024-03-09T21:12:26.241250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows_to_delete = []\n",
    "for idx, row in new_pred_df.iterrows():\n",
    "    if row.label == 'I-PHONE_NUM':\n",
    "        if row.token_str == ')':\n",
    "            rows_to_delete.append(idx)\n",
    "        elif not bool(re.search(r'\\d', row.token_str)):\n",
    "            rows_to_delete.append(idx)\n",
    "    elif row.label == 'B-EMAIL':\n",
    "        if '@' not in row.token_str:\n",
    "            rows_to_delete.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a0312a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:12:26.288265Z",
     "iopub.status.busy": "2024-03-09T21:12:26.288012Z",
     "iopub.status.idle": "2024-03-09T21:12:26.292707Z",
     "shell.execute_reply": "2024-03-09T21:12:26.291730Z"
    },
    "papermill": {
     "duration": 0.019765,
     "end_time": "2024-03-09T21:12:26.294837",
     "exception": false,
     "start_time": "2024-03-09T21:12:26.275072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_pred_df = new_pred_df.drop(rows_to_delete, axis=0, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0c006b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:12:26.319466Z",
     "iopub.status.busy": "2024-03-09T21:12:26.319233Z",
     "iopub.status.idle": "2024-03-09T21:12:26.323694Z",
     "shell.execute_reply": "2024-03-09T21:12:26.322779Z"
    },
    "papermill": {
     "duration": 0.019051,
     "end_time": "2024-03-09T21:12:26.325592",
     "exception": false,
     "start_time": "2024-03-09T21:12:26.306541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_pred_df[\"row_id\"] = list(range(len(new_pred_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d90b5fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:12:26.348998Z",
     "iopub.status.busy": "2024-03-09T21:12:26.348718Z",
     "iopub.status.idle": "2024-03-09T21:12:26.356709Z",
     "shell.execute_reply": "2024-03-09T21:12:26.356007Z"
    },
    "papermill": {
     "duration": 0.021805,
     "end_time": "2024-03-09T21:12:26.358753",
     "exception": false,
     "start_time": "2024-03-09T21:12:26.336948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_pred_df[[\"row_id\", \"document\", \"token\", \"label\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fd6031d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T21:12:26.383334Z",
     "iopub.status.busy": "2024-03-09T21:12:26.383046Z",
     "iopub.status.idle": "2024-03-09T21:12:26.396700Z",
     "shell.execute_reply": "2024-03-09T21:12:26.395882Z"
    },
    "papermill": {
     "duration": 0.027953,
     "end_time": "2024-03-09T21:12:26.398559",
     "exception": false,
     "start_time": "2024-03-09T21:12:26.370606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>token_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>482</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>483</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>741</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>742</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Estrada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>464</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>465</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Estrada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Gilberto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Gamboa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Sindy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Samaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>328</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>George</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nadine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Born</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>86</td>\n",
       "      <td>6</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Eladio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>86</td>\n",
       "      <td>7</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Amaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Silvia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Villalobos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>104</td>\n",
       "      <td>7</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Dr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>104</td>\n",
       "      <td>8</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sakir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>104</td>\n",
       "      <td>9</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Ahmad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>112</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Ferreira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>123</td>\n",
       "      <td>32</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Stefano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>33</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Lovato</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_id  document  token           label   token_str\n",
       "0        0         7      9  B-NAME_STUDENT    Nathalie\n",
       "1        1         7     10  I-NAME_STUDENT       Sylla\n",
       "2        2         7    482  B-NAME_STUDENT    Nathalie\n",
       "3        3         7    483  I-NAME_STUDENT       Sylla\n",
       "4        4         7    741  B-NAME_STUDENT    Nathalie\n",
       "5        5         7    742  I-NAME_STUDENT       Sylla\n",
       "6        6        10      0  B-NAME_STUDENT       Diego\n",
       "7        7        10      1  I-NAME_STUDENT     Estrada\n",
       "8        8        10    464  B-NAME_STUDENT       Diego\n",
       "9        9        10    465  I-NAME_STUDENT     Estrada\n",
       "10      10        16      4  B-NAME_STUDENT    Gilberto\n",
       "11      11        16      5  I-NAME_STUDENT      Gamboa\n",
       "12      12        20      5  B-NAME_STUDENT       Sindy\n",
       "13      13        20      6  I-NAME_STUDENT      Samaca\n",
       "14      14        20    328  B-NAME_STUDENT      George\n",
       "15      15        56     12  B-NAME_STUDENT      Nadine\n",
       "16      16        56     13  I-NAME_STUDENT        Born\n",
       "17      17        86      6  B-NAME_STUDENT      Eladio\n",
       "18      18        86      7  I-NAME_STUDENT       Amaya\n",
       "19      19        93      0  B-NAME_STUDENT      Silvia\n",
       "20      20        93      1  I-NAME_STUDENT  Villalobos\n",
       "21      21       104      7  B-NAME_STUDENT          Dr\n",
       "22      22       104      8  I-NAME_STUDENT       Sakir\n",
       "23      23       104      9  I-NAME_STUDENT       Ahmad\n",
       "24      24       112      5  B-NAME_STUDENT   Francisco\n",
       "25      25       112      6  I-NAME_STUDENT    Ferreira\n",
       "26      26       123     32  B-NAME_STUDENT     Stefano\n",
       "27      27       123     33  I-NAME_STUDENT      Lovato"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred_df[[\"row_id\", \"document\", \"token\", \"label\", \"token_str\"]]"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    },
    {
     "datasetId": 4385921,
     "sourceId": 7530253,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4415272,
     "sourceId": 7585184,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4441730,
     "sourceId": 7624642,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4364651,
     "isSourceIdPinned": true,
     "sourceId": 7669053,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4491573,
     "sourceId": 7709256,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4447414,
     "sourceId": 7733255,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4546325,
     "sourceId": 7771296,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 91.731811,
   "end_time": "2024-03-09T21:12:29.554704",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-09T21:10:57.822893",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
