{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f5c8e89",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-23T08:06:07.821370Z",
     "iopub.status.busy": "2024-04-23T08:06:07.820710Z",
     "iopub.status.idle": "2024-04-23T08:06:24.438879Z",
     "shell.execute_reply": "2024-04-23T08:06:24.438123Z"
    },
    "papermill": {
     "duration": 16.631424,
     "end_time": "2024-04-23T08:06:24.441108",
     "exception": false,
     "start_time": "2024-04-23T08:06:07.809684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 08:06:16.694385: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-23 08:06:16.694479: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-23 08:06:16.783651: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import argparse\n",
    "import os\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification, LongformerTokenizerFast\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d281a770",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:06:24.463187Z",
     "iopub.status.busy": "2024-04-23T08:06:24.462540Z",
     "iopub.status.idle": "2024-04-23T08:06:24.468606Z",
     "shell.execute_reply": "2024-04-23T08:06:24.467758Z"
    },
    "papermill": {
     "duration": 0.018901,
     "end_time": "2024-04-23T08:06:24.470562",
     "exception": false,
     "start_time": "2024-04-23T08:06:24.451661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INFERENCE_STRIDE = 256\n",
    "\n",
    "INFERENCE_MAX_LENGTH_NO_REPLACE = [1024, 1024, 1024, 1024, 1024, 1024, 1024]\n",
    "TRAINING_MODEL_PATH_NO_REPLACE = [\n",
    "    \"/kaggle/input/train-nb-lb0-976/checkpoint-900\",\n",
    "    \"/kaggle/input/kfold-ex-15-avg0-9755/fold0/model_0.9726/checkpoint-1900\",\n",
    "    \"/kaggle/input/kfold-ex-15-avg0-9755/fold3/model_0.9733/checkpoint-2000\",\n",
    "    \"/kaggle/input/kfold-ex-6-avg-0-9757/fold3/model_0.9735/checkpoint-1900\",\n",
    "    \"/kaggle/input/kfold-ex-4-avg-0-97515/fold1/model_0.9765/checkpoint-1800\",\n",
    "    \"/kaggle/input/train-and-nb-rewrite-1k-same-0-fix-500-no-label-1k/fold2/model_0.9767/checkpoint-1700\",\n",
    "    \"/kaggle/input/kfold-ex-5/fold0/model_0.9766/checkpoint-2600\"\n",
    "]\n",
    "\n",
    "INFERENCE_MAX_LENGTH_REPLACE = []\n",
    "TRAINING_MODEL_PATH_REPLACE = []  # 替换\\n\\n的\n",
    "\n",
    "TRAINING_MODEL_PATH = TRAINING_MODEL_PATH_NO_REPLACE + TRAINING_MODEL_PATH_REPLACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1820f5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:06:24.491490Z",
     "iopub.status.busy": "2024-04-23T08:06:24.491225Z",
     "iopub.status.idle": "2024-04-23T08:06:24.497766Z",
     "shell.execute_reply": "2024-04-23T08:06:24.496777Z"
    },
    "papermill": {
     "duration": 0.019299,
     "end_time": "2024-04-23T08:06:24.499606",
     "exception": false,
     "start_time": "2024-04-23T08:06:24.480307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    0: 'B-EMAIL',\n",
    "    1: 'B-ID_NUM',\n",
    "    2: 'B-NAME_STUDENT',\n",
    "    3: 'B-PHONE_NUM',\n",
    "    4: 'B-STREET_ADDRESS',\n",
    "    5: 'B-URL_PERSONAL',\n",
    "    6: 'B-USERNAME',\n",
    "    7: 'I-ID_NUM',\n",
    "    8: 'I-NAME_STUDENT',\n",
    "    9: 'I-PHONE_NUM',\n",
    "    10: 'I-STREET_ADDRESS',\n",
    "    11: 'I-URL_PERSONAL',\n",
    "    12: 'O'\n",
    "}\n",
    "label2id = {\n",
    "    'B-EMAIL': 0,\n",
    "    'B-ID_NUM': 1,\n",
    "    'B-NAME_STUDENT': 2,\n",
    "    'B-PHONE_NUM': 3,\n",
    "    'B-STREET_ADDRESS': 4,\n",
    "    'B-URL_PERSONAL': 5,\n",
    "    'B-USERNAME': 6,\n",
    "    'I-ID_NUM': 7,\n",
    "    'I-NAME_STUDENT': 8,\n",
    "    'I-PHONE_NUM': 9,\n",
    "    'I-STREET_ADDRESS': 10,\n",
    "    'I-URL_PERSONAL': 11,\n",
    "    'O': 12\n",
    "}\n",
    "all_labels = [\n",
    "    'B-EMAIL',\n",
    "    'B-ID_NUM',\n",
    "    'B-NAME_STUDENT',\n",
    "    'B-PHONE_NUM',\n",
    "    'B-STREET_ADDRESS',\n",
    "    'B-URL_PERSONAL',\n",
    "    'B-USERNAME',\n",
    "    'I-ID_NUM',\n",
    "    'I-NAME_STUDENT',\n",
    "    'I-PHONE_NUM',\n",
    "    'I-STREET_ADDRESS',\n",
    "    'I-URL_PERSONAL',\n",
    "    'O'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2fb50d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:06:24.520690Z",
     "iopub.status.busy": "2024-04-23T08:06:24.520413Z",
     "iopub.status.idle": "2024-04-23T08:06:24.531578Z",
     "shell.execute_reply": "2024-04-23T08:06:24.530770Z"
    },
    "papermill": {
     "duration": 0.023782,
     "end_time": "2024-04-23T08:06:24.533450",
     "exception": false,
     "start_time": "2024-04-23T08:06:24.509668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_labels(word_ids, word_labels):\n",
    "    label_ids = []\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            label_ids.append(-100)\n",
    "        else:\n",
    "            label_ids.append(label2id[word_labels[word_idx]])\n",
    "    return label_ids\n",
    "\n",
    "# Tokenize texts, possibly generating more than one tokenized sample for each text\n",
    "\n",
    "\n",
    "def tokenize(df, tokenizer, inference_max_length, to_tensor=True, with_labels=True):\n",
    "\n",
    "    # This is what's different from a longformer\n",
    "    # Read the parameters with attention\n",
    "    encoded = tokenizer(df['tokens'].tolist(),\n",
    "                        is_split_into_words=True,\n",
    "                        return_overflowing_tokens=True,\n",
    "                        stride=INFERENCE_STRIDE,\n",
    "                        max_length=inference_max_length,\n",
    "                        padding=\"max_length\",\n",
    "                        truncation=True)\n",
    "\n",
    "    if with_labels:\n",
    "        encoded['labels'] = []\n",
    "\n",
    "    encoded['wids'] = []\n",
    "    n = len(encoded['overflow_to_sample_mapping'])\n",
    "    for i in range(n):\n",
    "\n",
    "        # Map back to original row\n",
    "        text_idx = encoded['overflow_to_sample_mapping'][i]\n",
    "\n",
    "        # Get word indexes (this is a global index that takes into consideration the chunking :D )\n",
    "        word_ids = encoded.word_ids(i)\n",
    "\n",
    "        if with_labels:\n",
    "            # Get word labels of the full un-chunked text\n",
    "            word_labels = df['labels'].iloc[text_idx]\n",
    "\n",
    "            # Get the labels associated with the word indexes\n",
    "            label_ids = get_labels(word_ids, word_labels)\n",
    "            encoded['labels'].append(label_ids)\n",
    "        encoded['wids'].append([w if w is not None else -1 for w in word_ids])\n",
    "\n",
    "    if to_tensor:\n",
    "        encoded = {key: torch.as_tensor(val) for key, val in encoded.items()}\n",
    "    return encoded\n",
    "\n",
    "\n",
    "class PIIDataset(Dataset):\n",
    "    def __init__(self, tokenized_ds):\n",
    "        self.data = tokenized_ds\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = {k: self.data[k][index] for k in self.data.keys()}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "235aabfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:06:24.553981Z",
     "iopub.status.busy": "2024-04-23T08:06:24.553714Z",
     "iopub.status.idle": "2024-04-23T08:06:24.563170Z",
     "shell.execute_reply": "2024-04-23T08:06:24.562354Z"
    },
    "papermill": {
     "duration": 0.021842,
     "end_time": "2024-04-23T08:06:24.565073",
     "exception": false,
     "start_time": "2024-04-23T08:06:24.543231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inferenceV4(df, dl, model, gpu_id):\n",
    "\n",
    "    # These 2 dictionaries will hold text-level data\n",
    "    # Helping in the merging process by accumulating data\n",
    "    # Through all the chunks\n",
    "\n",
    "    token_pred = defaultdict(lambda: defaultdict(int))\n",
    "    token_cnt = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for batch in dl:\n",
    "        ids = batch[\"input_ids\"].to(devices[gpu_id])\n",
    "        mask = batch[\"attention_mask\"].to(devices[gpu_id])\n",
    "        preds = model(ids, attention_mask=mask, return_dict=False)[0].cpu().detach().numpy()\n",
    "        preds_softmax = np.exp(preds) / np.sum(np.exp(preds), axis=2).reshape(preds.shape[0], preds.shape[1], 1)\n",
    "\n",
    "        del ids, mask\n",
    "\n",
    "        # Go over each prediction, getting the text_id reference\n",
    "\n",
    "        for k, (chunk_preds, text_id) in enumerate(zip(preds_softmax, batch['overflow_to_sample_mapping'].tolist())):\n",
    "            # The word_ids are absolute references in the original text\n",
    "            word_ids = batch['wids'][k].numpy()\n",
    "\n",
    "            for idx, word_idx in enumerate(word_ids):\n",
    "                if word_idx != -1:\n",
    "                    token_pred[text_id][word_idx] += chunk_preds[idx]\n",
    "                    token_cnt[text_id][word_idx] += 1\n",
    "\n",
    "    for text_id in token_pred:\n",
    "        for word_idx in token_pred[text_id]:\n",
    "            token_pred[text_id][word_idx] /= token_cnt[text_id][word_idx]\n",
    "\n",
    "    return token_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7d74e77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:06:24.586523Z",
     "iopub.status.busy": "2024-04-23T08:06:24.586241Z",
     "iopub.status.idle": "2024-04-23T08:06:24.593204Z",
     "shell.execute_reply": "2024-04-23T08:06:24.592362Z"
    },
    "papermill": {
     "duration": 0.019309,
     "end_time": "2024-04-23T08:06:24.594989",
     "exception": false,
     "start_time": "2024-04-23T08:06:24.575680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_dict_tensor(input_dict):\n",
    "    split_dict_1 = {}\n",
    "    split_dict_2 = {}\n",
    "\n",
    "    for key, value in input_dict.items():\n",
    "        # 如果value不是张量，则尝试将其转换为张量\n",
    "        if not isinstance(value, torch.Tensor):\n",
    "            value = torch.tensor(value)\n",
    "\n",
    "        # 获取当前value的第一个维度长度\n",
    "        split_index = value.shape[0] // 2\n",
    "\n",
    "        # 如果value至少有一个元素，则尝试拆分\n",
    "        if value.shape[0] > 0:\n",
    "            split_value_1, split_value_2 = torch.split(tensor=value, split_size_or_sections=[split_index, value.shape[0] - split_index], dim=0)\n",
    "            split_dict_1[key] = split_value_1\n",
    "            split_dict_2[key] = split_value_2\n",
    "        else:\n",
    "            # 如果value为空，直接复制\n",
    "            split_dict_1[key] = value\n",
    "            split_dict_2[key] = value.clone()  # 确保是一个新的副本\n",
    "\n",
    "    return split_dict_1, split_dict_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ee124eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:06:24.615388Z",
     "iopub.status.busy": "2024-04-23T08:06:24.615129Z",
     "iopub.status.idle": "2024-04-23T08:06:24.872579Z",
     "shell.execute_reply": "2024-04-23T08:06:24.871674Z"
    },
    "papermill": {
     "duration": 0.269722,
     "end_time": "2024-04-23T08:06:24.874543",
     "exception": false,
     "start_time": "2024-04-23T08:06:24.604821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LIBRARIES TO CLEAN MEMORY\n",
    "import ctypes\n",
    "import gc\n",
    "import threading\n",
    "import time\n",
    "libc = ctypes.CDLL(\"libc.so.6\")\n",
    "_ = gc.collect()\n",
    "libc.malloc_trim(0)\n",
    "device0 = torch.device(\"cuda:0\")\n",
    "device1 = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc7fbb5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:06:24.896417Z",
     "iopub.status.busy": "2024-04-23T08:06:24.895598Z",
     "iopub.status.idle": "2024-04-23T08:06:24.933549Z",
     "shell.execute_reply": "2024-04-23T08:06:24.932675Z"
    },
    "papermill": {
     "duration": 0.050726,
     "end_time": "2024-04-23T08:06:24.935466",
     "exception": false,
     "start_time": "2024-04-23T08:06:24.884740",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(\"/kaggle/input/pii-detection-removal-from-educational-data/test.json\")\n",
    "df.tokens = df.tokens.apply(lambda x: [\"|\" if i == '\\n\\n' else i for i in x])\n",
    "\n",
    "final_token_pred = defaultdict(lambda: defaultdict(int))\n",
    "'''\n",
    "有点小问题，可能切分的时候会把一个文档的切成两个部分去推理，这样重合的部分的word没有很好的平均概率的时候，可能会有点问题\n",
    "'''\n",
    "for idx, model_path in enumerate(TRAINING_MODEL_PATH_REPLACE):\n",
    "\n",
    "    print('#' * 25)\n",
    "    print('=> Inferring', model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model0 = AutoModelForTokenClassification.from_pretrained(\n",
    "        model_path,\n",
    "        num_labels=len(all_labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "        ignore_mismatched_sizes=True\n",
    "    ).to(device0)\n",
    "    model1 = AutoModelForTokenClassification.from_pretrained(\n",
    "        model_path,\n",
    "        num_labels=len(all_labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "        ignore_mismatched_sizes=True\n",
    "    ).to(device1)\n",
    "    models = [model0, model1]\n",
    "    devices = [device0, device1]\n",
    "\n",
    "    # 这个tokenize成功运行\n",
    "    tokenized_test = tokenize(\n",
    "        df=df, \n",
    "        inference_max_length=INFERENCE_MAX_LENGTH_REPLACE[idx], \n",
    "        with_labels=False, \n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "    last_shape = list(tokenized_test.values())[0].shape[0]\n",
    "    for k, v in tokenized_test.items():\n",
    "        assert last_shape == v.shape[0]\n",
    "        last_shape = v.shape[0]\n",
    "\n",
    "    # 这个split成功运行\n",
    "    sub_df_1, sub_df_2 = split_dict_tensor(tokenized_test)  # 问题所在\n",
    "    # Create a lock to synchronize the threads\n",
    "    lock = threading.Lock()\n",
    "\n",
    "    single_pred = []\n",
    "    # Define a function for inference\n",
    "\n",
    "    def inference_thread(gpu_id, lock, tokenized_test):\n",
    "        with lock:\n",
    "            print(f\"Thread {gpu_id} started on GPU {gpu_id}\")\n",
    "        # 这里也没有问题\n",
    "        test_dataset = PIIDataset(tokenized_test)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=1)\n",
    "\n",
    "        token_pred = inferenceV4(df=df, dl=test_dataloader, model=models[gpu_id], gpu_id=gpu_id)\n",
    "        with lock:\n",
    "            print(f\"Thread {gpu_id} finished on GPU {gpu_id}\")\n",
    "\n",
    "        single_pred.append(token_pred)\n",
    "\n",
    "    # Create two threads for inference\n",
    "    thread1 = threading.Thread(target=inference_thread, args=(0, lock, sub_df_1))\n",
    "    thread2 = threading.Thread(target=inference_thread, args=(1, lock, sub_df_2))\n",
    "\n",
    "    # Start the threads\n",
    "    thread1.start()\n",
    "    thread2.start()\n",
    "\n",
    "    # Wait for both threads to finish\n",
    "    thread1.join()\n",
    "    thread2.join()\n",
    "\n",
    "    print(\"Both threads have finished.\")\n",
    "    print()\n",
    "    for tmp_pred in single_pred:\n",
    "        for text_id in tmp_pred:\n",
    "            for word_idx in tmp_pred[text_id]:\n",
    "                final_token_pred[text_id][word_idx] += tmp_pred[text_id][word_idx] / len(TRAINING_MODEL_PATH)\n",
    "\n",
    "    # CLEAN MEMORY\n",
    "    del model0, model1, models, tokenizer\n",
    "    torch.cuda.empty_cache()\n",
    "    _ = gc.collect()\n",
    "    libc.malloc_trim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26bf70e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:06:24.957330Z",
     "iopub.status.busy": "2024-04-23T08:06:24.956791Z",
     "iopub.status.idle": "2024-04-23T08:09:51.532945Z",
     "shell.execute_reply": "2024-04-23T08:09:51.532166Z"
    },
    "papermill": {
     "duration": 206.589598,
     "end_time": "2024-04-23T08:09:51.535349",
     "exception": false,
     "start_time": "2024-04-23T08:06:24.945751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "=> Inferring /kaggle/input/train-nb-lb0-976/checkpoint-900\n",
      "Thread 0 started on GPU 0\n",
      "Thread 1 started on GPU 1\n",
      "Thread 1 finished on GPU 1\n",
      "Thread 0 finished on GPU 0\n",
      "Both threads have finished.\n",
      "\n",
      "#########################\n",
      "=> Inferring /kaggle/input/kfold-ex-15-avg0-9755/fold0/model_0.9726/checkpoint-1900\n",
      "Thread 0 started on GPU 0\n",
      "Thread 1 started on GPU 1\n",
      "Thread 1 finished on GPU 1\n",
      "Thread 0 finished on GPU 0\n",
      "Both threads have finished.\n",
      "\n",
      "#########################\n",
      "=> Inferring /kaggle/input/kfold-ex-15-avg0-9755/fold3/model_0.9733/checkpoint-2000\n",
      "Thread 0 started on GPU 0\n",
      "Thread 1 started on GPU 1\n",
      "Thread 1 finished on GPU 1\n",
      "Thread 0 finished on GPU 0\n",
      "Both threads have finished.\n",
      "\n",
      "#########################\n",
      "=> Inferring /kaggle/input/kfold-ex-6-avg-0-9757/fold3/model_0.9735/checkpoint-1900\n",
      "Thread 0 started on GPU 0\n",
      "Thread 1 started on GPU 1\n",
      "Thread 1 finished on GPU 1\n",
      "Thread 0 finished on GPU 0\n",
      "Both threads have finished.\n",
      "\n",
      "#########################\n",
      "=> Inferring /kaggle/input/kfold-ex-4-avg-0-97515/fold1/model_0.9765/checkpoint-1800\n",
      "Thread 0 started on GPU 0\n",
      "Thread 1 started on GPU 1\n",
      "Thread 1 finished on GPU 1\n",
      "Thread 0 finished on GPU 0\n",
      "Both threads have finished.\n",
      "\n",
      "#########################\n",
      "=> Inferring /kaggle/input/train-and-nb-rewrite-1k-same-0-fix-500-no-label-1k/fold2/model_0.9767/checkpoint-1700\n",
      "Thread 0 started on GPU 0\n",
      "Thread 1 started on GPU 1\n",
      "Thread 1 finished on GPU 1\n",
      "Thread 0 finished on GPU 0\n",
      "Both threads have finished.\n",
      "\n",
      "#########################\n",
      "=> Inferring /kaggle/input/kfold-ex-5/fold0/model_0.9766/checkpoint-2600\n",
      "Thread 0 started on GPU 0\n",
      "Thread 1 started on GPU 1\n",
      "Thread 1 finished on GPU 1\n",
      "Thread 0 finished on GPU 0\n",
      "Both threads have finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"/kaggle/input/pii-detection-removal-from-educational-data/test.json\")\n",
    "'''\n",
    "有点小问题，可能切分的时候会把一个文档的切成两个部分去推理，这样重合的部分的word没有很好的平均概率的时候，可能会有点问题\n",
    "'''\n",
    "for idx, model_path in enumerate(TRAINING_MODEL_PATH_NO_REPLACE):\n",
    "\n",
    "    print('#' * 25)\n",
    "    print('=> Inferring', model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model0 = AutoModelForTokenClassification.from_pretrained(\n",
    "        model_path,\n",
    "        num_labels=len(all_labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "        ignore_mismatched_sizes=True\n",
    "    ).to(device0)\n",
    "    model1 = AutoModelForTokenClassification.from_pretrained(\n",
    "        model_path,\n",
    "        num_labels=len(all_labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "        ignore_mismatched_sizes=True\n",
    "    ).to(device1)\n",
    "    models = [model0, model1]\n",
    "    devices = [device0, device1]\n",
    "\n",
    "    # 这个tokenize成功运行\n",
    "    tokenized_test = tokenize(\n",
    "        df=df, \n",
    "        inference_max_length=INFERENCE_MAX_LENGTH_NO_REPLACE[idx], \n",
    "        with_labels=False, \n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "    last_shape = list(tokenized_test.values())[0].shape[0]\n",
    "    for k, v in tokenized_test.items():\n",
    "        assert last_shape == v.shape[0]\n",
    "        last_shape = v.shape[0]\n",
    "\n",
    "    # 这个split成功运行\n",
    "    sub_df_1, sub_df_2 = split_dict_tensor(tokenized_test)  # 问题所在\n",
    "    # Create a lock to synchronize the threads\n",
    "    lock = threading.Lock()\n",
    "\n",
    "    single_pred = []\n",
    "    # Define a function for inference\n",
    "\n",
    "    def inference_thread(gpu_id, lock, tokenized_test):\n",
    "        with lock:\n",
    "            print(f\"Thread {gpu_id} started on GPU {gpu_id}\")\n",
    "        # 这里也没有问题\n",
    "        test_dataset = PIIDataset(tokenized_test)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=1)\n",
    "\n",
    "        token_pred = inferenceV4(df=df, dl=test_dataloader, model=models[gpu_id], gpu_id=gpu_id)\n",
    "        with lock:\n",
    "            print(f\"Thread {gpu_id} finished on GPU {gpu_id}\")\n",
    "\n",
    "        single_pred.append(token_pred)\n",
    "\n",
    "    # Create two threads for inference\n",
    "    thread1 = threading.Thread(target=inference_thread, args=(0, lock, sub_df_1))\n",
    "    thread2 = threading.Thread(target=inference_thread, args=(1, lock, sub_df_2))\n",
    "\n",
    "    # Start the threads\n",
    "    thread1.start()\n",
    "    thread2.start()\n",
    "\n",
    "    # Wait for both threads to finish\n",
    "    thread1.join()\n",
    "    thread2.join()\n",
    "\n",
    "    print(\"Both threads have finished.\")\n",
    "    print()\n",
    "    for tmp_pred in single_pred:\n",
    "        for text_id in tmp_pred:\n",
    "            for word_idx in tmp_pred[text_id]:\n",
    "                final_token_pred[text_id][word_idx] += tmp_pred[text_id][word_idx] / len(TRAINING_MODEL_PATH)\n",
    "\n",
    "    # CLEAN MEMORY\n",
    "    del model0, model1, models, tokenizer\n",
    "    torch.cuda.empty_cache()\n",
    "    _ = gc.collect()\n",
    "    libc.malloc_trim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3612bb71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:09:51.563496Z",
     "iopub.status.busy": "2024-04-23T08:09:51.563166Z",
     "iopub.status.idle": "2024-04-23T08:09:51.624153Z",
     "shell.execute_reply": "2024-04-23T08:09:51.623409Z"
    },
    "papermill": {
     "duration": 0.077467,
     "end_time": "2024-04-23T08:09:51.626312",
     "exception": false,
     "start_time": "2024-04-23T08:09:51.548845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "document, token, label, score = [], [], [], []\n",
    "for text_id in final_token_pred:\n",
    "    for word_idx in final_token_pred[text_id]:\n",
    "        pred = final_token_pred[text_id][word_idx].argmax(-1)\n",
    "        pred_without_O = final_token_pred[text_id][word_idx][:12].argmax(-1)\n",
    "        if final_token_pred[text_id][word_idx][12] < 0.0:\n",
    "            final_pred = pred_without_O\n",
    "            tmp_score = final_token_pred[text_id][word_idx][final_pred]\n",
    "\n",
    "        else:\n",
    "            final_pred = pred\n",
    "            tmp_score = final_token_pred[text_id][word_idx][final_pred]\n",
    "\n",
    "        if id2label[final_pred] != 'O':\n",
    "            document.append(df.loc[text_id, \"document\"])\n",
    "            token.append(word_idx)\n",
    "            label.append(id2label[final_pred])\n",
    "            score.append(tmp_score)\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"document\": document,\n",
    "    \"token\": token,\n",
    "    \"label\": label,\n",
    "    \"score\": score\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16ebc1c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:09:51.652029Z",
     "iopub.status.busy": "2024-04-23T08:09:51.651728Z",
     "iopub.status.idle": "2024-04-23T08:09:51.665123Z",
     "shell.execute_reply": "2024-04-23T08:09:51.664389Z"
    },
    "papermill": {
     "duration": 0.028645,
     "end_time": "2024-04-23T08:09:51.667302",
     "exception": false,
     "start_time": "2024-04-23T08:09:51.638657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_df = pred_df.sort_values(['document', 'token']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89608623",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:09:51.692655Z",
     "iopub.status.busy": "2024-04-23T08:09:51.692378Z",
     "iopub.status.idle": "2024-04-23T08:09:51.709997Z",
     "shell.execute_reply": "2024-04-23T08:09:51.709031Z"
    },
    "papermill": {
     "duration": 0.032582,
     "end_time": "2024-04-23T08:09:51.712064",
     "exception": false,
     "start_time": "2024-04-23T08:09:51.679482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>0.998984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>0.999279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>482</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>0.998687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>483</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>0.999035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>741</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>0.998682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>742</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>0.999107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>0.999248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>0.999502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>464</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>0.998569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>465</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>0.998825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>0.999431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>0.999353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>0.999007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>0.999048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>328</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>0.813513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20</td>\n",
       "      <td>330</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>0.712766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>0.999390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>0.999354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>86</td>\n",
       "      <td>6</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>0.999270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86</td>\n",
       "      <td>7</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>0.999146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>0.999274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>0.999044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>104</td>\n",
       "      <td>7</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>0.496632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>104</td>\n",
       "      <td>8</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>0.995606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>104</td>\n",
       "      <td>9</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>0.999154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>0.999465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>112</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>0.999466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>123</td>\n",
       "      <td>32</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>0.999261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>123</td>\n",
       "      <td>33</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>0.999028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    document  token           label     score\n",
       "0          7      9  B-NAME_STUDENT  0.998984\n",
       "1          7     10  I-NAME_STUDENT  0.999279\n",
       "2          7    482  B-NAME_STUDENT  0.998687\n",
       "3          7    483  I-NAME_STUDENT  0.999035\n",
       "4          7    741  B-NAME_STUDENT  0.998682\n",
       "5          7    742  I-NAME_STUDENT  0.999107\n",
       "6         10      0  B-NAME_STUDENT  0.999248\n",
       "7         10      1  I-NAME_STUDENT  0.999502\n",
       "8         10    464  B-NAME_STUDENT  0.998569\n",
       "9         10    465  I-NAME_STUDENT  0.998825\n",
       "10        16      4  B-NAME_STUDENT  0.999431\n",
       "11        16      5  I-NAME_STUDENT  0.999353\n",
       "12        20      5  B-NAME_STUDENT  0.999007\n",
       "13        20      6  I-NAME_STUDENT  0.999048\n",
       "14        20    328  B-NAME_STUDENT  0.813513\n",
       "15        20    330  B-NAME_STUDENT  0.712766\n",
       "16        56     12  B-NAME_STUDENT  0.999390\n",
       "17        56     13  I-NAME_STUDENT  0.999354\n",
       "18        86      6  B-NAME_STUDENT  0.999270\n",
       "19        86      7  I-NAME_STUDENT  0.999146\n",
       "20        93      0  B-NAME_STUDENT  0.999274\n",
       "21        93      1  I-NAME_STUDENT  0.999044\n",
       "22       104      7  B-NAME_STUDENT  0.496632\n",
       "23       104      8  B-NAME_STUDENT  0.995606\n",
       "24       104      9  I-NAME_STUDENT  0.999154\n",
       "25       112      5  B-NAME_STUDENT  0.999465\n",
       "26       112      6  I-NAME_STUDENT  0.999466\n",
       "27       123     32  B-NAME_STUDENT  0.999261\n",
       "28       123     33  I-NAME_STUDENT  0.999028"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858ee052",
   "metadata": {
    "papermill": {
     "duration": 0.01227,
     "end_time": "2024-04-23T08:09:51.736726",
     "exception": false,
     "start_time": "2024-04-23T08:09:51.724456",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7105102",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:09:51.762235Z",
     "iopub.status.busy": "2024-04-23T08:09:51.761919Z",
     "iopub.status.idle": "2024-04-23T08:09:51.768142Z",
     "shell.execute_reply": "2024-04-23T08:09:51.767169Z"
    },
    "papermill": {
     "duration": 0.021475,
     "end_time": "2024-04-23T08:09:51.770225",
     "exception": false,
     "start_time": "2024-04-23T08:09:51.748750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[['document', 'tokens']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eaf8f50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:09:51.796270Z",
     "iopub.status.busy": "2024-04-23T08:09:51.795942Z",
     "iopub.status.idle": "2024-04-23T08:09:51.809849Z",
     "shell.execute_reply": "2024-04-23T08:09:51.808810Z"
    },
    "papermill": {
     "duration": 0.029761,
     "end_time": "2024-04-23T08:09:51.812049",
     "exception": false,
     "start_time": "2024-04-23T08:09:51.782288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.explode(['tokens']).reset_index(drop=True).rename(columns={'tokens': 'token'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "268f98cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:09:51.837539Z",
     "iopub.status.busy": "2024-04-23T08:09:51.837303Z",
     "iopub.status.idle": "2024-04-23T08:09:51.844733Z",
     "shell.execute_reply": "2024-04-23T08:09:51.843991Z"
    },
    "papermill": {
     "duration": 0.022388,
     "end_time": "2024-04-23T08:09:51.846796",
     "exception": false,
     "start_time": "2024-04-23T08:09:51.824408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['token_str'] = df['token']\n",
    "df['token'] = df.groupby('document').cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba0ceb13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:09:51.872398Z",
     "iopub.status.busy": "2024-04-23T08:09:51.871837Z",
     "iopub.status.idle": "2024-04-23T08:09:51.882200Z",
     "shell.execute_reply": "2024-04-23T08:09:51.881390Z"
    },
    "papermill": {
     "duration": 0.025231,
     "end_time": "2024-04-23T08:09:51.884083",
     "exception": false,
     "start_time": "2024-04-23T08:09:51.858852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_pred_df = pd.merge(df, pred_df[['document', 'token', 'label', \"score\"]], on=['document', 'token'], how='left')\n",
    "new_pred_df['label'] = new_pred_df['label'].fillna('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "903fb86b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:09:51.908762Z",
     "iopub.status.busy": "2024-04-23T08:09:51.908508Z",
     "iopub.status.idle": "2024-04-23T08:09:51.923192Z",
     "shell.execute_reply": "2024-04-23T08:09:51.922364Z"
    },
    "papermill": {
     "duration": 0.029268,
     "end_time": "2024-04-23T08:09:51.925040",
     "exception": false,
     "start_time": "2024-04-23T08:09:51.895772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pp(new_pred_df):\n",
    "    df = new_pred_df.copy()\n",
    "    i = 0\n",
    "    while i < len(df):\n",
    "        st = i\n",
    "        doc = df.loc[st, \"document\"]\n",
    "        tok = df.loc[st, \"token\"]\n",
    "        pred_tok = df.loc[st, \"label\"]\n",
    "        if pred_tok == 'O':\n",
    "            i += 1\n",
    "            continue\n",
    "        lab = pred_tok.split('-')[1]\n",
    "        cur_doc = doc\n",
    "        cur_lab = lab\n",
    "        last_tok = tok\n",
    "        cur_tok = last_tok\n",
    "        # prefix = []\n",
    "        while i < len(df) and cur_doc == doc and cur_lab == lab and last_tok == cur_tok:\n",
    "            # prefix.append(pred_tok.split('-')[0])\n",
    "            last_tok = cur_tok + 1\n",
    "            i += 1\n",
    "            cur_doc = df.loc[i, \"document\"]\n",
    "            cur_tok = df.loc[i, \"token\"]\n",
    "            if i >= len(df) or df.loc[i, \"label\"] == 'O':\n",
    "                break\n",
    "            cur_lab = df.loc[i, \"label\"].split('-')[1]\n",
    "\n",
    "        # exception\n",
    "        if st - 2 >= 0 and df.loc[st - 2, \"document\"] == df.loc[st, \"document\"] and df.loc[st - 1, \"token_str\"] == '\\n' and df.loc[st - 2, \"label\"] != 'O' and df.loc[st - 2, \"label\"].split('-')[1] == lab:\n",
    "            df.loc[st - 1, \"label\"] = 'I-' + lab\n",
    "            df.loc[st - 1, \"score\"] = 1\n",
    "            for j in range(st, i):\n",
    "                if df.loc[j, \"label\"] != 'I-' + lab:\n",
    "                    df.loc[j, \"score\"] = 1\n",
    "                    df.loc[j, \"label\"] = 'I-' + lab\n",
    "            continue\n",
    "\n",
    "        # fix\n",
    "        for j in range(st, i):\n",
    "            if j == st:\n",
    "                if df.loc[j, \"label\"] != 'B-' + lab:\n",
    "                    df.loc[j, \"score\"] = 1\n",
    "                    df.loc[j, \"label\"] = 'B-' + lab\n",
    "            else:\n",
    "                if df.loc[j, \"label\"] != 'I-' + lab:\n",
    "                    df.loc[j, \"score\"] = 1\n",
    "                    df.loc[j, \"label\"] = 'I-' + lab\n",
    "#         print(df.loc[st:i,:])\n",
    "        if lab == 'NAME_STUDENT' and any(len(item) == 2 and item[0].isupper() and item[1] == \".\" for item in df.loc[st:i-1, 'token_str']):\n",
    "            for j in range(st, i):\n",
    "                df.loc[j, \"score\"] = 0\n",
    "                df.loc[j, \"label\"] = 'O'\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4de5f646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:09:51.949665Z",
     "iopub.status.busy": "2024-04-23T08:09:51.949409Z",
     "iopub.status.idle": "2024-04-23T08:09:52.378173Z",
     "shell.execute_reply": "2024-04-23T08:09:52.377370Z"
    },
    "papermill": {
     "duration": 0.44382,
     "end_time": "2024-04-23T08:09:52.380607",
     "exception": false,
     "start_time": "2024-04-23T08:09:51.936787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_pred_df = pp(new_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c304b6bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:09:52.406031Z",
     "iopub.status.busy": "2024-04-23T08:09:52.405701Z",
     "iopub.status.idle": "2024-04-23T08:09:52.417938Z",
     "shell.execute_reply": "2024-04-23T08:09:52.417118Z"
    },
    "papermill": {
     "duration": 0.027064,
     "end_time": "2024-04-23T08:09:52.419811",
     "exception": false,
     "start_time": "2024-04-23T08:09:52.392747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>token_str</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Design</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Thinking</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>for</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>innovation</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>reflexion</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8500</th>\n",
       "      <td>123</td>\n",
       "      <td>1689</td>\n",
       "      <td>(</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8501</th>\n",
       "      <td>123</td>\n",
       "      <td>1690</td>\n",
       "      <td>https://www.melessa.uni-</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8502</th>\n",
       "      <td>123</td>\n",
       "      <td>1691</td>\n",
       "      <td>muenchen.de/team/vorstandssprecher/schmidt/pub...</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8503</th>\n",
       "      <td>123</td>\n",
       "      <td>1692</td>\n",
       "      <td>)</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8504</th>\n",
       "      <td>123</td>\n",
       "      <td>1693</td>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8505 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      document  token                                          token_str  \\\n",
       "0            7      0                                             Design   \n",
       "1            7      1                                           Thinking   \n",
       "2            7      2                                                for   \n",
       "3            7      3                                         innovation   \n",
       "4            7      4                                          reflexion   \n",
       "...        ...    ...                                                ...   \n",
       "8500       123   1689                                                  (   \n",
       "8501       123   1690                           https://www.melessa.uni-   \n",
       "8502       123   1691  muenchen.de/team/vorstandssprecher/schmidt/pub...   \n",
       "8503       123   1692                                                  )   \n",
       "8504       123   1693                                               \\n\\n   \n",
       "\n",
       "     label  score  \n",
       "0        O    NaN  \n",
       "1        O    NaN  \n",
       "2        O    NaN  \n",
       "3        O    NaN  \n",
       "4        O    NaN  \n",
       "...    ...    ...  \n",
       "8500     O    NaN  \n",
       "8501     O    NaN  \n",
       "8502     O    NaN  \n",
       "8503     O    NaN  \n",
       "8504     O    NaN  \n",
       "\n",
       "[8505 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a11213f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:09:52.445756Z",
     "iopub.status.busy": "2024-04-23T08:09:52.445490Z",
     "iopub.status.idle": "2024-04-23T08:09:52.455695Z",
     "shell.execute_reply": "2024-04-23T08:09:52.454816Z"
    },
    "papermill": {
     "duration": 0.02572,
     "end_time": "2024-04-23T08:09:52.458375",
     "exception": false,
     "start_time": "2024-04-23T08:09:52.432655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_pred_df = new_pred_df.query(\"label != 'O'\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e66e2b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:09:52.486857Z",
     "iopub.status.busy": "2024-04-23T08:09:52.486543Z",
     "iopub.status.idle": "2024-04-23T08:09:52.494653Z",
     "shell.execute_reply": "2024-04-23T08:09:52.493746Z"
    },
    "papermill": {
     "duration": 0.023759,
     "end_time": "2024-04-23T08:09:52.496579",
     "exception": false,
     "start_time": "2024-04-23T08:09:52.472820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows_to_delete = []\n",
    "for idx, row in new_pred_df.iterrows():\n",
    "    if row.label == 'I-PHONE_NUM':\n",
    "        if row.token_str == ')':\n",
    "            rows_to_delete.append(idx)\n",
    "        elif not bool(re.search(r'\\d', row.token_str)):\n",
    "            rows_to_delete.append(idx)\n",
    "    elif row.label == 'B-EMAIL':\n",
    "        if '@' not in row.token_str:\n",
    "            rows_to_delete.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "746c502b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:09:52.523119Z",
     "iopub.status.busy": "2024-04-23T08:09:52.522838Z",
     "iopub.status.idle": "2024-04-23T08:09:52.527417Z",
     "shell.execute_reply": "2024-04-23T08:09:52.526622Z"
    },
    "papermill": {
     "duration": 0.02044,
     "end_time": "2024-04-23T08:09:52.529373",
     "exception": false,
     "start_time": "2024-04-23T08:09:52.508933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_pred_df = new_pred_df.drop(rows_to_delete, axis=0, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "872ecadc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:09:52.556119Z",
     "iopub.status.busy": "2024-04-23T08:09:52.555354Z",
     "iopub.status.idle": "2024-04-23T08:09:52.559952Z",
     "shell.execute_reply": "2024-04-23T08:09:52.559134Z"
    },
    "papermill": {
     "duration": 0.019433,
     "end_time": "2024-04-23T08:09:52.561830",
     "exception": false,
     "start_time": "2024-04-23T08:09:52.542397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_pred_df[\"row_id\"] = list(range(len(new_pred_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5aee368c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:09:52.713011Z",
     "iopub.status.busy": "2024-04-23T08:09:52.712735Z",
     "iopub.status.idle": "2024-04-23T08:09:52.719778Z",
     "shell.execute_reply": "2024-04-23T08:09:52.719069Z"
    },
    "papermill": {
     "duration": 0.021965,
     "end_time": "2024-04-23T08:09:52.721671",
     "exception": false,
     "start_time": "2024-04-23T08:09:52.699706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_pred_df[[\"row_id\", \"document\", \"token\", \"label\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48e783b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T08:09:52.748410Z",
     "iopub.status.busy": "2024-04-23T08:09:52.748145Z",
     "iopub.status.idle": "2024-04-23T08:09:52.763121Z",
     "shell.execute_reply": "2024-04-23T08:09:52.762204Z"
    },
    "papermill": {
     "duration": 0.030635,
     "end_time": "2024-04-23T08:09:52.765113",
     "exception": false,
     "start_time": "2024-04-23T08:09:52.734478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>token_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>482</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>483</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>741</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>742</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Estrada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>464</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>465</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Estrada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Gilberto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Gamboa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Sindy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Samaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>328</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>George</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>330</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Geoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nadine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Born</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>86</td>\n",
       "      <td>6</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Eladio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>86</td>\n",
       "      <td>7</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Amaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Silvia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Villalobos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>104</td>\n",
       "      <td>7</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Dr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>104</td>\n",
       "      <td>8</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sakir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>104</td>\n",
       "      <td>9</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Ahmad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>112</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Ferreira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>123</td>\n",
       "      <td>32</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Stefano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>123</td>\n",
       "      <td>33</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Lovato</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_id  document  token           label   token_str\n",
       "0        0         7      9  B-NAME_STUDENT    Nathalie\n",
       "1        1         7     10  I-NAME_STUDENT       Sylla\n",
       "2        2         7    482  B-NAME_STUDENT    Nathalie\n",
       "3        3         7    483  I-NAME_STUDENT       Sylla\n",
       "4        4         7    741  B-NAME_STUDENT    Nathalie\n",
       "5        5         7    742  I-NAME_STUDENT       Sylla\n",
       "6        6        10      0  B-NAME_STUDENT       Diego\n",
       "7        7        10      1  I-NAME_STUDENT     Estrada\n",
       "8        8        10    464  B-NAME_STUDENT       Diego\n",
       "9        9        10    465  I-NAME_STUDENT     Estrada\n",
       "10      10        16      4  B-NAME_STUDENT    Gilberto\n",
       "11      11        16      5  I-NAME_STUDENT      Gamboa\n",
       "12      12        20      5  B-NAME_STUDENT       Sindy\n",
       "13      13        20      6  I-NAME_STUDENT      Samaca\n",
       "14      14        20    328  B-NAME_STUDENT      George\n",
       "15      15        20    330  B-NAME_STUDENT       Geoff\n",
       "16      16        56     12  B-NAME_STUDENT      Nadine\n",
       "17      17        56     13  I-NAME_STUDENT        Born\n",
       "18      18        86      6  B-NAME_STUDENT      Eladio\n",
       "19      19        86      7  I-NAME_STUDENT       Amaya\n",
       "20      20        93      0  B-NAME_STUDENT      Silvia\n",
       "21      21        93      1  I-NAME_STUDENT  Villalobos\n",
       "22      22       104      7  B-NAME_STUDENT          Dr\n",
       "23      23       104      8  I-NAME_STUDENT       Sakir\n",
       "24      24       104      9  I-NAME_STUDENT       Ahmad\n",
       "25      25       112      5  B-NAME_STUDENT   Francisco\n",
       "26      26       112      6  I-NAME_STUDENT    Ferreira\n",
       "27      27       123     32  B-NAME_STUDENT     Stefano\n",
       "28      28       123     33  I-NAME_STUDENT      Lovato"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred_df[[\"row_id\", \"document\", \"token\", \"label\", \"token_str\"]]"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    },
    {
     "datasetId": 4385921,
     "sourceId": 7530253,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4415272,
     "sourceId": 7585184,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4441730,
     "sourceId": 7624642,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4491573,
     "sourceId": 7709256,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4447414,
     "sourceId": 7733255,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4617709,
     "sourceId": 7869832,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4661747,
     "sourceId": 7931027,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4667804,
     "sourceId": 7939647,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4781869,
     "sourceId": 8098179,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4807402,
     "sourceId": 8133166,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4828175,
     "sourceId": 8160840,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4832995,
     "sourceId": 8167219,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4854734,
     "sourceId": 8196082,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4782189,
     "sourceId": 8098589,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4782186,
     "sourceId": 8098586,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4782183,
     "sourceId": 8098582,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 230.191295,
   "end_time": "2024-04-23T08:09:55.345383",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-23T08:06:05.154088",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
